{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nweY2PYTMR-N"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefarine/DMML2022_ROLEX/blob/main/with_doc2vec_0_63.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Importation"
      ],
      "metadata": {
        "id": "W13Q5dmEWEGf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7DTMc8x6SBXo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('training_data.csv')\n",
        "df_pred = pd.read_csv('unlabelled_test_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OU5qw3Dp3Xzg",
        "outputId": "bae164ff-5d38-4baa-85d5-b86ae6bf1d2b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence\n",
              "0        0  Nous dûmes nous excuser des propos que nous eû...\n",
              "1        1  Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2        2  Et, paradoxalement, boire froid n'est pas la b...\n",
              "3        3  Ce n'est pas étonnant, car c'est une saison my...\n",
              "4        4  Le corps de Golo lui-même, d'une essence aussi...\n",
              "...    ...                                                ...\n",
              "1195  1195  C'est un phénomène qui trouve une accélération...\n",
              "1196  1196  Je vais parler au serveur et voir si on peut d...\n",
              "1197  1197  Il n'était pas comme tant de gens qui par pare...\n",
              "1198  1198      Ils deviennent dangereux pour notre économie.\n",
              "1199  1199  Son succès a généré beaucoup de réactions néga...\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a5d789c-95ed-4c6c-9237-edf11c9b05f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1195</td>\n",
              "      <td>C'est un phénomène qui trouve une accélération...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1196</td>\n",
              "      <td>Je vais parler au serveur et voir si on peut d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>Il n'était pas comme tant de gens qui par pare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1198</td>\n",
              "      <td>Ils deviennent dangereux pour notre économie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1199</td>\n",
              "      <td>Son succès a généré beaucoup de réactions néga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a5d789c-95ed-4c6c-9237-edf11c9b05f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a5d789c-95ed-4c6c-9237-edf11c9b05f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a5d789c-95ed-4c6c-9237-edf11c9b05f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Hh3vpynrWLgi",
        "outputId": "5e483b36-2461-4209-990b-99aedbe29f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty\n",
              "0   0  Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2   2  Le test de niveau en français est sur le site ...         A1\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   4  Dans les écoles de commerce, dans les couloirs...         B1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-653ad2e7-26d5-46bd-a210-f7fc04176f60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-653ad2e7-26d5-46bd-a210-f7fc04176f60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-653ad2e7-26d5-46bd-a210-f7fc04176f60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-653ad2e7-26d5-46bd-a210-f7fc04176f60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head()\n",
        "X_pred = df_pred['sentence']\n",
        "X_pred"
      ],
      "metadata": {
        "id": "NFlTAKsIjBMS",
        "outputId": "ddfd21a5-c900-43fb-a3d5-7165a89ff858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Nous dûmes nous excuser des propos que nous eû...\n",
              "1       Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2       Et, paradoxalement, boire froid n'est pas la b...\n",
              "3       Ce n'est pas étonnant, car c'est une saison my...\n",
              "4       Le corps de Golo lui-même, d'une essence aussi...\n",
              "                              ...                        \n",
              "1195    C'est un phénomène qui trouve une accélération...\n",
              "1196    Je vais parler au serveur et voir si on peut d...\n",
              "1197    Il n'était pas comme tant de gens qui par pare...\n",
              "1198        Ils deviennent dangereux pour notre économie.\n",
              "1199    Son succès a généré beaucoup de réactions néga...\n",
              "Name: sentence, Length: 1200, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed = 0"
      ],
      "metadata": {
        "id": "x8jCm9ZHWV-B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['difficulty']\n",
        "X = df['sentence']"
      ],
      "metadata": {
        "id": "lOKAN5MvXjTO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "dwbHmmYiWab5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_rate = (df['difficulty'].value_counts().max()/df['difficulty'].shape[0]).round(4)\n",
        "base_rate"
      ],
      "metadata": {
        "id": "Na9oFoNHWj9U",
        "outputId": "1b8cf8ea-c40c-49f2-a4d3-042222e9c457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression (whithout data cleaning)\n"
      ],
      "metadata": {
        "id": "kAwHrHOwX5fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "ZctKHudHX_hw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using default tokenizer in TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n"
      ],
      "metadata": {
        "id": "qIestHk0Y4r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "M_yVAG8zaSwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=0)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "fS0gAoGlnHNE",
        "outputId": "a8c4aa88-1b13-49bd-cdaf-27ac8ca83750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-3d913fd9c0a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fit model on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2152\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"processes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[1;32m   2155\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m     coefs, Cs, n_iter = _logistic_regression_path(\n\u001b[0m\u001b[1;32m   1061\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             ]\n\u001b[0;32m--> 806\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    807\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"newton-cg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mfit_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# csr_matvecs or csc_matvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvecs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0m\u001b[1;32m    492\u001b[0m            other.ravel(), result.ravel())\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "#WHICH AVERAGE MODE IS BETTER ?#\n",
        "################################\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate(true, pred):\n",
        "    precision = precision_score(true, pred,average='macro')\n",
        "    recall = recall_score(true, pred,average='macro')\n",
        "    f1 = f1_score(true, pred,average='macro')\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "hTesOv1vuo81"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "metadata": {
        "id": "uEZEvn11uvFU",
        "outputId": "caa378eb-b186-4f1e-ac4f-9f3dc0eb410f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[93 31 21 10  4  2]\n",
            " [54 60 30  6  6  8]\n",
            " [12 38 64 17  9 20]\n",
            " [ 6  6 15 66 27 24]\n",
            " [ 4  4 10 37 73 45]\n",
            " [ 7  8  8 19 24 92]]\n",
            "ACCURACY SCORE:\n",
            "0.4667\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4645\n",
            "\tRecall: 0.4677\n",
            "\tF1_Score: 0.4640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipe.predict(X_pred)\n",
        "\n",
        "predictions = pd.DataFrame(predictions,columns=['difficulty'])\n",
        "\n",
        "predictions.to_csv(\"LogisticRegression.csv\")"
      ],
      "metadata": {
        "id": "fUv634Q6wTNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN (whithout data cleaning)"
      ],
      "metadata": {
        "id": "3tUIDbw2HEA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define classifier\n",
        "classifier_knn = KNeighborsClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe_knn = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier_knn)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_knn.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_knn = pipe_knn.predict(X_test)\n",
        "\n",
        "evaluate(y_test, y_pred_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01jRIxK5G9i7",
        "outputId": "eba052d3-c2e2-4a51-f251-f4b0f2ce04e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[121  28   8   1   1   2]\n",
            " [ 98  51  12   1   1   1]\n",
            " [ 81  39  33   3   1   3]\n",
            " [ 49  30  19  29   3  14]\n",
            " [ 48  36  29  15  29  16]\n",
            " [ 37  29  17  23   9  43]]\n",
            "ACCURACY SCORE:\n",
            "0.3187\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4007\n",
            "\tRecall: 0.3183\n",
            "\tF1_Score: 0.3022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_knn = pipe_knn.predict(X_pred)\n",
        "\n",
        "predictions_knn = pd.DataFrame(predictions_knn,columns=['difficulty'])\n",
        "\n",
        "predictions_knn.to_csv(\"KNN.csv\")"
      ],
      "metadata": {
        "id": "FGPMpi4-W-ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN improved"
      ],
      "metadata": {
        "id": "XPelT33EKDn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search - hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameters to test\n",
        "grid = {'n_neighbors':np.arange(1,100),\n",
        "        'p':np.arange(1,3),\n",
        "        'weights':['uniform','distance']}\n",
        "\n",
        "# Define and fit model\n",
        "knn = KNeighborsClassifier()\n",
        "classifier_knn_plus = GridSearchCV(knn, grid, cv=10)\n",
        "\n",
        "pipe_knn_plus = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier_knn_plus)])\n",
        "\n",
        "pipe_knn_plus.fit(X_train, y_train)\n",
        "\n",
        "print(\"Hyperparameters:\", classifier_knn_plus.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zICrinP2KFRX",
        "outputId": "4effd5a3-46b1-4f32-e62c-8d753dfa6d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred_knn_plus = pipe_knn_plus.predict(X_test)\n",
        "\n",
        "evaluate(y_test, y_pred_knn_plus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPwNctU9R_h2",
        "outputId": "b8492409-fee2-429b-ea69-2e14f37c72dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[116  27  14   1   1   2]\n",
            " [ 79  64  15   4   1   1]\n",
            " [ 65  38  44   8   2   3]\n",
            " [ 37  25  23  40   2  17]\n",
            " [ 37  30  23  26  36  21]\n",
            " [ 34  22  19  13  17  53]]\n",
            "ACCURACY SCORE:\n",
            "0.3677\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4227\n",
            "\tRecall: 0.3678\n",
            "\tF1_Score: 0.3575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_knn_plus = pipe_knn_plus.predict(X_pred)\n",
        "\n",
        "predictions_knn_plus = pd.DataFrame(predictions_knn_plus,columns=['difficulty'])\n",
        "\n",
        "predictions_knn_plus.to_csv(\"Knn_plus.csv\")"
      ],
      "metadata": {
        "id": "zr5uitrAXIn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier (without data cleaning)"
      ],
      "metadata": {
        "id": "YwKRk7DqHO65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define classifier\n",
        "classifier_dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe_dtc = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier_dtc)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_dtc.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_dtc = pipe_dtc.predict(X_test)\n",
        "\n",
        "evaluate(y_test, y_pred_dtc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_GI5gPVHTl8",
        "outputId": "a3e6bf53-beda-47ec-b6d4-ab71cb8312d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[82 35 25  8  2  9]\n",
            " [44 54 39 15  4  8]\n",
            " [28 38 38 23 16 17]\n",
            " [ 7 20 27 40 28 22]\n",
            " [10 19 33 36 40 35]\n",
            " [12 12 28 38 32 36]]\n",
            "ACCURACY SCORE:\n",
            "0.3021\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3021\n",
            "\tRecall: 0.3022\n",
            "\tF1_Score: 0.2994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_dtc = pipe_dtc.predict(X_pred)\n",
        "\n",
        "predictions_dtc = pd.DataFrame(predictions_dtc,columns=['difficulty'])\n",
        "\n",
        "predictions_dtc.to_csv(\"DecisionTreeClassifier.csv\")"
      ],
      "metadata": {
        "id": "1GtKGXU-XV-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier (without data cleaning)"
      ],
      "metadata": {
        "id": "hHlGKn-dHPlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define classifier\n",
        "classifier_rfc = RandomForestClassifier()\n",
        "\n",
        "# Create pipeline\n",
        "pipe_rfc = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier_rfc)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_rfc.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_rfc = pipe_rfc.predict(X_test)\n",
        "\n",
        "evaluate(y_test, y_pred_rfc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1MvDvZyIKIu",
        "outputId": "c6b15a0f-a7fc-4b94-8d1e-5670c8703bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[121  22  11   4   2   1]\n",
            " [ 82  51  18  11   2   0]\n",
            " [ 35  39  54  18   7   7]\n",
            " [ 18  11  13  65  24  13]\n",
            " [ 12  10  29  52  47  23]\n",
            " [ 15  10  17  32  23  61]]\n",
            "ACCURACY SCORE:\n",
            "0.4156\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4250\n",
            "\tRecall: 0.4182\n",
            "\tF1_Score: 0.4059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_rfc = pipe_rfc.predict(X_pred)\n",
        "\n",
        "predictions_rfc = pd.DataFrame(predictions_rfc,columns=['difficulty'])\n",
        "\n",
        "predictions_rfc.to_csv(\"RandomForestClassifier.csv\")"
      ],
      "metadata": {
        "id": "oDVzIs9jXetS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove stopwords\n",
        "\n"
      ],
      "metadata": {
        "id": "zC26hXIu7K46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and update spaCy\n",
        "!pip install -U spacy\n",
        "\n",
        "# Download the French language model\n",
        "!python -m spacy download fr\n",
        "\n",
        "!python -m spacy download fr_core_news_sm\n",
        "\n",
        "!pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git &> /dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GSXRp1j7W6F",
        "outputId": "fd24b52c-00fa-4953-f2da-f9acf69cf98e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-18 00:35:18.320508: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'fr' are deprecated. Please use the\n",
            "full pipeline package name 'fr_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.4.0/fr_core_news_sm-3.4.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from fr-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-18 00:35:31.778872: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-sm==3.4.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.4.0/fr_core_news_sm-3.4.0-py3-none-any.whl (16.3 MB)\n",
            "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from fr-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nlp = spacy.load('fr_core_news_sm')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "529vlYf27hHi",
        "outputId": "544b8e68-dd4b-40cf-c55d-cee2314e7d7c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to lowercase\n",
        "df['sentence'] = df['sentence'].str.lower()\n",
        "df_pred['sentence'] = df_pred['sentence'].str.lower()\n",
        "# Define the function to remove the punctuation\n",
        "def remove_punctuations(text):\n",
        "    for punctuation in string.punctuation:\n",
        "        text = text.replace(punctuation, \" \")\n",
        "    return text\n",
        "\n",
        "\n",
        "# Remove punctuation\n",
        "df['sentence'] = df['sentence'].apply(remove_punctuations)\n",
        "df_pred['sentence'] = df_pred['sentence'].apply(remove_punctuations)\n",
        "df_pred.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Sab5aMvu7q8A",
        "outputId": "7350234a-9e07-4a42-9a36-d614e93c2ed4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence\n",
              "0   0  nous dûmes nous excuser des propos que nous eû...\n",
              "1   1  vous ne pouvez pas savoir le plaisir que j ai ...\n",
              "2   2  et  paradoxalement  boire froid n est pas la b...\n",
              "3   3  ce n est pas étonnant  car c est une saison my...\n",
              "4   4  le corps de golo lui même  d une essence aussi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6dcb82d-5fb7-495a-a146-8f2a4a0c6825\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>nous dûmes nous excuser des propos que nous eû...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>vous ne pouvez pas savoir le plaisir que j ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>et  paradoxalement  boire froid n est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ce n est pas étonnant  car c est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>le corps de golo lui même  d une essence aussi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6dcb82d-5fb7-495a-a146-8f2a4a0c6825')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6dcb82d-5fb7-495a-a146-8f2a4a0c6825 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6dcb82d-5fb7-495a-a146-8f2a4a0c6825');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define list of stopwords\n",
        "\n",
        "french_stopwords = spacy.lang.fr.stop_words.STOP_WORDS\n",
        "french_stopwords.add('a')\n",
        "french_stopwords.add('c')\n",
        "french_stopwords.add('d')\n",
        "french_stopwords.add('e')\n",
        "french_stopwords.add('j')\n",
        "french_stopwords.add('l')\n",
        "french_stopwords.add('m')\n",
        "french_stopwords.add('n')\n",
        "french_stopwords.add('s')\n",
        "french_stopwords.add('t')\n",
        "french_stopwords.add('y')\n",
        "french_stopwords.add('qu')"
      ],
      "metadata": {
        "id": "-BLabqta8i_t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove stopwords\n",
        "df['sentence'] = df['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (french_stopwords)]))\n",
        "df_pred['sentence'] = df_pred['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (french_stopwords)]))\n",
        "df_pred.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JvCKao757-h8",
        "outputId": "6baff894-35fb-4155-b7d8-b1788b8456d5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence\n",
              "0   0               dûmes excuser propos eûmes prononcés\n",
              "1   1      pouvez savoir plaisir recevoir bonne nouvelle\n",
              "2   2            paradoxalement boire froid bonne parade\n",
              "3   3                        étonnant saison mystérieuse\n",
              "4   4  corps golo essence surnaturelle monture arrang...\n",
              "5   5  jeta cri petit cri voulut dresser débattre rep...\n",
              "6   6  madame monsieur fils léo arrive jours retard é...\n",
              "7   7                                  trouvé repas midi\n",
              "8   8  racine mal bel bien penser tendant manichéisme...\n",
              "9   9                                             madame"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-baed17af-66f4-4e07-82ca-4cf8c7163e29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>dûmes excuser propos eûmes prononcés</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>pouvez savoir plaisir recevoir bonne nouvelle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>paradoxalement boire froid bonne parade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>étonnant saison mystérieuse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>corps golo essence surnaturelle monture arrang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>jeta cri petit cri voulut dresser débattre rep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>madame monsieur fils léo arrive jours retard é...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>trouvé repas midi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>racine mal bel bien penser tendant manichéisme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>madame</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baed17af-66f4-4e07-82ca-4cf8c7163e29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-baed17af-66f4-4e07-82ca-4cf8c7163e29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-baed17af-66f4-4e07-82ca-4cf8c7163e29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "nlp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "df['tocken_without_stopwords'] = [nlp(text) for text in df.sentence]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mGFd0NX68Mqd",
        "outputId": "72b8b59f-9663-4364-ea90-4bdc40f68a2b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty  \\\n",
              "0   0  coûts kilométriques réels diverger sensiblemen...         C1   \n",
              "1   1                    bleu couleur préférée aime vert         A1   \n",
              "2   2           test niveau français site internet école         A1   \n",
              "3   3                                        mari boston         A1   \n",
              "4   4  écoles commerce couloirs places financières ar...         B1   \n",
              "\n",
              "                            tocken_without_stopwords  \n",
              "0  (coûts, kilométriques, réels, diverger, sensib...  \n",
              "1              (bleu, couleur, préférée, aime, vert)  \n",
              "2    (test, niveau, français, site, internet, école)  \n",
              "3                                     (mari, boston)  \n",
              "4  (écoles, commerce, couloirs, places, financièr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f2190da-6ddd-4049-9620-7610672a8502\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>tocken_without_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>coûts kilométriques réels diverger sensiblemen...</td>\n",
              "      <td>C1</td>\n",
              "      <td>(coûts, kilométriques, réels, diverger, sensib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bleu couleur préférée aime vert</td>\n",
              "      <td>A1</td>\n",
              "      <td>(bleu, couleur, préférée, aime, vert)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test niveau français site internet école</td>\n",
              "      <td>A1</td>\n",
              "      <td>(test, niveau, français, site, internet, école)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mari boston</td>\n",
              "      <td>A1</td>\n",
              "      <td>(mari, boston)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>écoles commerce couloirs places financières ar...</td>\n",
              "      <td>B1</td>\n",
              "      <td>(écoles, commerce, couloirs, places, financièr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f2190da-6ddd-4049-9620-7610672a8502')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f2190da-6ddd-4049-9620-7610672a8502 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f2190da-6ddd-4049-9620-7610672a8502');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add a columns with the lengh \n",
        "df['len'] = [len(token) for token in df.tocken_without_stopwords]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b-Cjx1VQ8XG1",
        "outputId": "703683e6-9568-4b19-a45e-dbd34582e678"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty  \\\n",
              "0   0  coûts kilométriques réels diverger sensiblemen...         C1   \n",
              "1   1                    bleu couleur préférée aime vert         A1   \n",
              "2   2           test niveau français site internet école         A1   \n",
              "3   3                                        mari boston         A1   \n",
              "4   4  écoles commerce couloirs places financières ar...         B1   \n",
              "\n",
              "                            tocken_without_stopwords  len  \n",
              "0  (coûts, kilométriques, réels, diverger, sensib...   21  \n",
              "1              (bleu, couleur, préférée, aime, vert)    5  \n",
              "2    (test, niveau, français, site, internet, école)    6  \n",
              "3                                     (mari, boston)    2  \n",
              "4  (écoles, commerce, couloirs, places, financièr...   19  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cda3086-c381-4ace-9bf8-f5d6a8288591\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>tocken_without_stopwords</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>coûts kilométriques réels diverger sensiblemen...</td>\n",
              "      <td>C1</td>\n",
              "      <td>(coûts, kilométriques, réels, diverger, sensib...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bleu couleur préférée aime vert</td>\n",
              "      <td>A1</td>\n",
              "      <td>(bleu, couleur, préférée, aime, vert)</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test niveau français site internet école</td>\n",
              "      <td>A1</td>\n",
              "      <td>(test, niveau, français, site, internet, école)</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mari boston</td>\n",
              "      <td>A1</td>\n",
              "      <td>(mari, boston)</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>écoles commerce couloirs places financières ar...</td>\n",
              "      <td>B1</td>\n",
              "      <td>(écoles, commerce, couloirs, places, financièr...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cda3086-c381-4ace-9bf8-f5d6a8288591')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cda3086-c381-4ace-9bf8-f5d6a8288591 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cda3086-c381-4ace-9bf8-f5d6a8288591');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming"
      ],
      "metadata": {
        "id": "Xg1sAitUD-0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(language='french')\n",
        "\n",
        "def return_stem(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    return [stemmer.stem(X.text) for X in doc]"
      ],
      "metadata": {
        "id": "PkriENsQDpNV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['stemmed'] = [return_stem(text) for text in df.sentence]\n",
        "df_pred['stemmed'] = [return_stem(text) for text in df_pred.sentence]"
      ],
      "metadata": {
        "id": "QJNPCcy3EOhT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = pd.factorize(df['difficulty'])[0] + 1"
      ],
      "metadata": {
        "id": "Fir_yKOgHx9p"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head()"
      ],
      "metadata": {
        "id": "mD2upX224K-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "G7UIBJBFEV8b",
        "outputId": "112b94fb-db98-4350-dc4d-37cb19431dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                           sentence difficulty  \\\n",
              "0   0  coûts kilométriques réels diverger sensiblemen...         C1   \n",
              "1   1                    bleu couleur préférée aime vert         A1   \n",
              "2   2           test niveau français site internet école         A1   \n",
              "3   3                                        mari boston         A1   \n",
              "4   4  écoles commerce couloirs places financières ar...         B1   \n",
              "\n",
              "                            tocken_without_stopwords  len  \\\n",
              "0  (coûts, kilométriques, réels, diverger, sensib...   21   \n",
              "1              (bleu, couleur, préférée, aime, vert)    5   \n",
              "2    (test, niveau, français, site, internet, école)    6   \n",
              "3                                     (mari, boston)    2   \n",
              "4  (écoles, commerce, couloirs, places, financièr...   19   \n",
              "\n",
              "                                             stemmed  label  \n",
              "0  [coût, kilometr, réel, diverg, sensibl, valeur...      1  \n",
              "1                 [bleu, couleur, préfer, aim, vert]      2  \n",
              "2         [test, niveau, franc, sit, internet, écol]      2  \n",
              "3                                      [mar, boston]      2  \n",
              "4  [écol, commerc, couloir, plac, financi, arriv,...      3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36c99823-5633-4afe-a6ca-0642f590f349\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>tocken_without_stopwords</th>\n",
              "      <th>len</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>coûts kilométriques réels diverger sensiblemen...</td>\n",
              "      <td>C1</td>\n",
              "      <td>(coûts, kilométriques, réels, diverger, sensib...</td>\n",
              "      <td>21</td>\n",
              "      <td>[coût, kilometr, réel, diverg, sensibl, valeur...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bleu couleur préférée aime vert</td>\n",
              "      <td>A1</td>\n",
              "      <td>(bleu, couleur, préférée, aime, vert)</td>\n",
              "      <td>5</td>\n",
              "      <td>[bleu, couleur, préfer, aim, vert]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>test niveau français site internet école</td>\n",
              "      <td>A1</td>\n",
              "      <td>(test, niveau, français, site, internet, école)</td>\n",
              "      <td>6</td>\n",
              "      <td>[test, niveau, franc, sit, internet, écol]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>mari boston</td>\n",
              "      <td>A1</td>\n",
              "      <td>(mari, boston)</td>\n",
              "      <td>2</td>\n",
              "      <td>[mar, boston]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>écoles commerce couloirs places financières ar...</td>\n",
              "      <td>B1</td>\n",
              "      <td>(écoles, commerce, couloirs, places, financièr...</td>\n",
              "      <td>19</td>\n",
              "      <td>[écol, commerc, couloir, plac, financi, arriv,...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36c99823-5633-4afe-a6ca-0642f590f349')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36c99823-5633-4afe-a6ca-0642f590f349 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36c99823-5633-4afe-a6ca-0642f590f349');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word2vec\n"
      ],
      "metadata": {
        "id": "hQBOUt1Q5CQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAbaVfI5Hin",
        "outputId": "ea3473ee-c2b6-4aa5-d095-c24d4d1e31e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.20.8-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.20.8\n",
            "  Downloading Levenshtein-0.20.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.20.8 python-Levenshtein-0.20.8 rapidfuzz-2.13.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import utils\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "import nltk"
      ],
      "metadata": {
        "id": "VvBplIIe5Wpm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "testdocuments = []\n",
        "for ind in df.index:\n",
        "  documents.append(TaggedDocument(df['stemmed'][ind],\n",
        "      [df['label'][ind]]))\n",
        "\n",
        "for ind in df_pred.index:\n",
        "  testdocuments.append(TaggedDocument(df_pred['stemmed'][ind],\n",
        "      tags=None))\n",
        "testdocuments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji4dphVoIxxt",
        "outputId": "9784c947-d73d-4295-c496-39c95f44f1b9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['dûm', 'excus', 'propos', 'eûm', 'prononc'], tags=None),\n",
              " TaggedDocument(words=['pouv', 'savoir', 'plais', 'recevoir', 'bon', 'nouvel'], tags=None),\n",
              " TaggedDocument(words=['paradoxal', 'boir', 'froid', 'bon', 'parad'], tags=None),\n",
              " TaggedDocument(words=['éton', 'saison', 'mystéri'], tags=None),\n",
              " TaggedDocument(words=['corp', 'golo', 'essenc', 'surnaturel', 'montur', 'arrang', 'obstacl', 'matériel', 'objet', 'gên', 'rencontr', 'pren', 'ossatur', 'rend', 'intérieur', 'fût', 'bouton', 'port', 'adapt', 'aussitôt', 'surnag', 'invincibl', 'rob', 'roug', 'figur', 'pâl', 'nobl', 'mélancol', 'laiss', 'paraîtr', 'aucun', 'troubl', 'transvertebr'], tags=None),\n",
              " TaggedDocument(words=['jet', 'cri', 'pet', 'cri', 'voulut', 'dress', 'débattr', 'repouss', 'ced', 'forc', 'eût', 'manqu', 'résist'], tags=None),\n",
              " TaggedDocument(words=['madam', 'monsieur', 'fil', 'léo', 'arriv', 'jour', 'retard', 'écol'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'rep', 'mid'], tags=None),\n",
              " TaggedDocument(words=['racin', 'mal', 'bel', 'bien', 'pens', 'tend', 'maniché', 'néfast', 'néfast', 'respect', 'opin', 'divergent', 'débat', 'estompent', 'prof', 'extrem', 'uniform', 'pens'], tags=None),\n",
              " TaggedDocument(words=['madam'], tags=None),\n",
              " TaggedDocument(words=[], tags=None),\n",
              " TaggedDocument(words=['rempl', 'pot', 'eau', 'mis', 'glaçon'], tags=None),\n",
              " TaggedDocument(words=['pourt', 'distanc', 'vélo', 'mod', 'transport', 'perform', 'milieu', 'urbain', 'sem', 'urbain'], tags=None),\n",
              " TaggedDocument(words=['jeun', 'retraité', 'éduc', 'national', 'rog', 'rougi', 'répons'], tags=None),\n",
              " TaggedDocument(words=['enfant', 'drôl'], tags=None),\n",
              " TaggedDocument(words=['jeud', 'mard', 'aller', 'à', 'écol'], tags=None),\n",
              " TaggedDocument(words=['tomb', 'arbre', 'écras', 'structur', 'écras', 'arbre'], tags=None),\n",
              " TaggedDocument(words=['dois', 'achet', 'tub', 'peintur', 'bleu', 'fin', 'tableau'], tags=None),\n",
              " TaggedDocument(words=['appel', 'joy', 'parl', 'entend', 'sup', 'bien'], tags=None),\n",
              " TaggedDocument(words=['enfant', 'garçon', 'fill'], tags=None),\n",
              " TaggedDocument(words=['mirag', 'confus', 'égar', 'esper', 'esper', 'grandeur', 'succes', 'renomm', 'fortun', 'amour', 'aperçut', 'coup', 'pareil', 'guirland', 'figur', 'déroulent', 'ciel', 'apothéos', 'process', 'femm', 'éleg', 'rich', 'puiss', 'pass', 'souri', 'disparaîtr', 'fond', 'nuag', 'dor', 'rêv'], tags=None),\n",
              " TaggedDocument(words=['sci', 'scient', 'cypres', 'sci', 'scient', 'cypres'], tags=None),\n",
              " TaggedDocument(words=['semain', 'emploi', 'faveur', 'entend', 'combattr'], tags=None),\n",
              " TaggedDocument(words=['sanction', 'administr', 'ordon', 'pénal', 'nouveau', 'détenteur', 'chien', 'renoncent', 'format', 'achev'], tags=None),\n",
              " TaggedDocument(words=['ange', 'apparaît', 'fois', 'conseil', 'pêcheur'], tags=None),\n",
              " TaggedDocument(words=['homm', 'regard', 'sex', 'symbol', 'transcend', 'puissanc', 'tir', 'vanitécomm', 'muscl', 'stri', 'temp', 'grâc', 'magiqu', 'libert', 'rich', 'contingent', 'don', 'don', 'libr', 'voulu', 'aspect', 'contradictoir', 'enchant', 'soupçon', 'leurr', 'organ', 'prétend', 'affirm', 'obéit', 'lourd', 'désir', 'inassouv', 'érig', 'inopin', 'soulag', 'rêv', 'manifest', 'vital', 'suspect', 'caprici'], tags=None),\n",
              " TaggedDocument(words=['aiment', 'pass', 'journ', 'ensembl', 'bord', 'mer'], tags=None),\n",
              " TaggedDocument(words=['17h'], tags=None),\n",
              " TaggedDocument(words=['sort', 'précipit', 'eût', 'mis', 'chapeau'], tags=None),\n",
              " TaggedDocument(words=['retir', 'chapeau', 'feutr', 'gant', 'cuir', 'assier', 'silenc'], tags=None),\n",
              " TaggedDocument(words=['accord'], tags=None),\n",
              " TaggedDocument(words=['orphelin', 'orphelin', 'enfant', 'perdu', 'parent', 'parent'], tags=None),\n",
              " TaggedDocument(words=['excus', 'perdu', 'pouv', 'aid'], tags=None),\n",
              " TaggedDocument(words=['mond', 'fonction'], tags=None),\n",
              " TaggedDocument(words=['perdu', 'boît', 'mis', 'bijoux'], tags=None),\n",
              " TaggedDocument(words=['décid', 'install'], tags=None),\n",
              " TaggedDocument(words=['plasm', 'conserv', 'pourr', 'utilis', 'don', 'donneur', 'mois', 'rével', 'aucun', 'marqueur', 'infecti'], tags=None),\n",
              " TaggedDocument(words=['journal', 'voulu', 'savoir', 'pouv', 'rencontr'], tags=None),\n",
              " TaggedDocument(words=['aim', 'nouvel', 'rob'], tags=None),\n",
              " TaggedDocument(words=['vit', 'paris', 'parent', 'petit', 'soeur', 'jul', 'âgé', '8', 'an'], tags=None),\n",
              " TaggedDocument(words=['fair', 'heur', 'cour', 'pos', 'problem', 'vu', 'journ', 'scolair'], tags=None),\n",
              " TaggedDocument(words=['assis', 'terr', 'quarti', 'tourist', 'vieux', 'lyon', 'jam', 'sirot', 'limonad', 'bien', 'fraîch', 'chaleur', 'estival', 'journ', 'explor', 'rével', 'fatig'], tags=None),\n",
              " TaggedDocument(words=['homm', 'fut', 'grossi', 'parl', 'interromp'], tags=None),\n",
              " TaggedDocument(words=['2001', 'rosal', 'expliqu', 'onu', 'aupres', 'group', 'travail', 'peupl', 'autochton', 'surv', 'bison', 'sauvag', 'essentiel', 'symbol', 'indien', 'plain', 'bison', 'été', 'animal', 'sacr', 'indien', 'plain', 'crucial', 'cultur'], tags=None),\n",
              " TaggedDocument(words=['somm', 'être', 'visuel', 'rétinien', 'oublion', 'audit', 'acoust', 'jouent', 'rôl', 'percept', 'environ', 'remarqu', 'christian', 'hugonnet', 'président', 'semain', 'tient', '21', 'janvi', '3', 'févri', '2019'], tags=None),\n",
              " TaggedDocument(words=['voir', 'bréviair', 'manuscr', 'conserv', 'bibliothequ', 'grand', 'séminair', 'malin', 'incun', 'cambr'], tags=None),\n",
              " TaggedDocument(words=['laiss', 'gliss', 'terr', 'part', 'tromb', 'salon'], tags=None),\n",
              " TaggedDocument(words=['comt', 'usag', 'pri', 'point', 'divulgu', 'trist', 'vérit', 'fais', 'confident', 'avez', 'extrêm', 'indulgent', 'ajout', 'continu', 'recevoir', '16', 'distinct', 'extérieur', 'accord', 'amant', 'regn', 'trouv', 'plac', 'conven'], tags=None),\n",
              " TaggedDocument(words=['dat', 'mariag'], tags=None),\n",
              " TaggedDocument(words=['soir', 'hiv', 'aim', 'bien', 'lir', 'chemin', 'fair', 'cuisin'], tags=None),\n",
              " TaggedDocument(words=['valid', 'segment', 'identif', 'nombr', 'optimal', 'compart', 'été', 'fond', 'analys', 'statist', 'utilis', 'densit', 'campagnol', 'terrestr', 'estim', 'tach', 'annuel', '1989', '2004', 'cas', 'partit', 'bien', 'adapt', 'distingu', 'zon', 'dynam', 'démograph', 'don', 'suppos', 'présent', 'variabl', 'faibl', 'intérieur', 'compart', 'compart'], tags=None),\n",
              " TaggedDocument(words=['ici', 'bureau'], tags=None),\n",
              " TaggedDocument(words=['final', 'halloween', 'mis', 'vingtain', 'anné', 'impos', 'trouv', 'plac', 'societ', 'français'], tags=None),\n",
              " TaggedDocument(words=['aim', 'bien', 'fair', 'cuisin', 'temp', 'temp'], tags=None),\n",
              " TaggedDocument(words=[], tags=None),\n",
              " TaggedDocument(words=['évolu', 'surcharg', 'pondéral', 'obes', 'constat', 'grand', 'région', 'glob'], tags=None),\n",
              " TaggedDocument(words=['loin', 'effervescent', 'cuisin', 'chef', 'retrouv', 'magg', 'chaulet', 'créatric', 'propriétair', 'jardin', 'tropical', 'abrit', 'restaur'], tags=None),\n",
              " TaggedDocument(words=['plan', 'rigueur', 'succèdent', 'pay', 'remédi', 'déficit', 'rever', 'médaill', 'entraîn', 'mécontent', 'général', 'votent', 'part', 'national', 'propos', 'sort', 'euro'], tags=None),\n",
              " TaggedDocument(words=['futur', 'capac', 'support', 'transport', 'form', 'numer', 'don', 'point', 'augment', 'grâc', 'développ', 'fibr', 'optiqu', 'system', 'satellitair'], tags=None),\n",
              " TaggedDocument(words=['souhait', 'fair', 'fortun', 'prend', 'chemin'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'greff', 'électron', 'disposit', 'entrepreneur'], tags=None),\n",
              " TaggedDocument(words=['train', 'lav', 'vaissel', 'main'], tags=None),\n",
              " TaggedDocument(words=['galopin', 'villag', 'jeu', 'ébat', 'trac', 'pent', 'monticul', 'imperceptibl', 'senti'], tags=None),\n",
              " TaggedDocument(words=['preuv', 'million', 'emplois', 'europ', 'nécessit', 'compétent', 'scientif', 'technolog', 'pourvus', 'rien', 'secteur', 'informat', 'manqu', 'programmeur'], tags=None),\n",
              " TaggedDocument(words=['soleil', 'incandescent', 'jeun', 'coupl', 'yiddish', 'mar', 'houpp'], tags=None),\n",
              " TaggedDocument(words=['franc', 'attach', 'paus', 'dominical'], tags=None),\n",
              " TaggedDocument(words=['canard', 'eurent', 'bel', 'occas', 'pondr', 'oeuf', 'couleur'], tags=None),\n",
              " TaggedDocument(words=['non', 'termin', 'étud', 'juin', 'derni'], tags=None),\n",
              " TaggedDocument(words=['entam', 'programm', 'cursus'], tags=None),\n",
              " TaggedDocument(words=['assur', 'fois', 'repos', 'richess', 'pourt', 'évit', 'jam', 'pénetr', 'loin', 'lisi', 'tronc', 'espac', 'permet', 'apercevoir', 'champ', 'maison', 'profondeur', 'mystéri', 'sourc', 'terreur'], tags=None),\n",
              " TaggedDocument(words=[], tags=None),\n",
              " TaggedDocument(words=['numéro', 'mondial', 'facil', 'remport', 'final', 'manch', 'pein', 'heur', 'jeu'], tags=None),\n",
              " TaggedDocument(words=['femm', 'scientif', 'peinent', 'reconnu', 'social'], tags=None),\n",
              " TaggedDocument(words=['pass', 'nuit', 'révis', 'rapport', 'annuel'], tags=None),\n",
              " TaggedDocument(words=['mani', 'trait', 'bison', 'trait', 'indien', 'rosal'], tags=None),\n",
              " TaggedDocument(words=['vois', 'bien', 'trist', 'dis', 'rien', 'sour'], tags=None),\n",
              " TaggedDocument(words=['situat', 'étrang'], tags=None),\n",
              " TaggedDocument(words=['nomm', 'juillet', '2020', 'ex', 'déput', 'somm', 'jou', 'gros', 'examen', 'projet', 'loi', 'climat', 'résilient', 'commiss', 'spécial', 'assembl', 'national', 'part', 'lund', '8', 'mar'], tags=None),\n",
              " TaggedDocument(words=['trouvent', 'pai', 'dégueul'], tags=None),\n",
              " TaggedDocument(words=['détest', 'virus', 'effet', 'bénef', 'fut', 'prison'], tags=None),\n",
              " TaggedDocument(words=['rapport', 'nom', 'famill'], tags=None),\n",
              " TaggedDocument(words=['ador', 'petit', 'histoir'], tags=None),\n",
              " TaggedDocument(words=['somment', 'conscient', 'difficult', 'expédit', 'assumon', 'risqu'], tags=None),\n",
              " TaggedDocument(words=['esprit', 'hiv', 'décid', 'pun', 'arbre', 'apport', 'aid', 'oiseau'], tags=None),\n",
              " TaggedDocument(words=['pos', 'sac', 'chais'], tags=None),\n",
              " TaggedDocument(words=['définit', 'clair', 'simpl', 'pourt', 'définit', 'évolu', '9', 'décembr', '1905', 'dat', 'loi', 'sépar', 'églis', 'état', 'été', 'adopt'], tags=None),\n",
              " TaggedDocument(words=['réunion', 'hi', 'pris', 'décis', 'partenair', 'brésilien'], tags=None),\n",
              " TaggedDocument(words=['entraîn', 'capac', 'apprendr', 'langu', 'étranger'], tags=None),\n",
              " TaggedDocument(words=['2017', '34', '6', 'popul', 'vit', 'ménag', 'cred', 'leasing', 'petit', 'crédit', 'crédit', 'consomm', 'achat', 'acompt', 'det', 'aupres', 'famill', 'amis', 'viv', 'ménag', 'hypothequ', 'log', 'secondair'], tags=None),\n",
              " TaggedDocument(words=['homm', 'hésit', 'accueil', 'hôt', 'présentent', 'risqu', 'perdr', 'vi'], tags=None),\n",
              " TaggedDocument(words=['asil', 'ferm', 'bistrot', 'mus', 'entrecroisent', 'mouv', 'balanci', 'descript', 'sordid', 'périod', 'apais', 'fourn', 'journ', 'réuss', 'mendiqu', 'excentr', 'poet', 'anarch', 'emil', 'szitti', 'rencontr', 'stuttgart'], tags=None),\n",
              " TaggedDocument(words=['lund', 'david', 'journ', 'écol', 'soir', 'pratiqu', 'activ', 'musical', 'piano'], tags=None),\n",
              " TaggedDocument(words=['nom', 'emprunt', 'jeu', 'mot', 'qualif', 'nom', 'juif', 'serv', 'mieux', 'attir', 'client', 'it', 'all', 'good', 'man', 'devient', 'saul', 'goodman'], tags=None),\n",
              " TaggedDocument(words=['voir', 'succed', 'naissanc', 'univer', 'évolu', 'espec', 'humain', 'innov', 'technolog', 'conduisent', 'appart', 'jeun', 'surdou', 'personnag', 'mangent', 'ensembl'], tags=None),\n",
              " TaggedDocument(words=['activ', 'fair', 'domicil'], tags=None),\n",
              " TaggedDocument(words=['récompens', 'gentilless', 'pet', 'oiseau'], tags=None),\n",
              " TaggedDocument(words=['fé', 'réapparu', 'fois', 'forêt'], tags=None),\n",
              " TaggedDocument(words=['oui', 'trop', 'long'], tags=None),\n",
              " TaggedDocument(words=['viennent', 'sall', 'spectacl', 'rideau', 'ouvrent', 'couleur', 'mis', 'scen', 'bull', 'flamm', 'fum'], tags=None),\n",
              " TaggedDocument(words=['raison', 'bilingu', 'breton', 'franc', 'paraît', 'particuli', 'défend', 'ici', 'compt', 'avantag', 'mention', 'enfant', 'commenc', 'tôt', 'immers', 'grand', 'bel', 'langu', 'celtiqu'], tags=None),\n",
              " TaggedDocument(words=['option', 'fer', 'part', 'pist', 'rapport', 'aven', 'retrait', 'officiel', 'rem', 'semain', 'prochain', 'appui', 'gouvern', 'réform', 'prévu', 'ici', 'fin', 'anné'], tags=None),\n",
              " TaggedDocument(words=['remédi', 'échel', 'milit', 'commenc', 'organis', 'propr', 'fili', 'import', 'fin', 'anné', '1960'], tags=None),\n",
              " TaggedDocument(words=['inquiet', 'beaucoup', 'relat'], tags=None),\n",
              " TaggedDocument(words=['décid', 'aller', 'voir', 'avez', 'chois', 'beau', 'fauteuil'], tags=None),\n",
              " TaggedDocument(words=['défin', 'contraint', 'chos', 'impos', 'extérieur', 'contr', 'volont', 'individu'], tags=None),\n",
              " TaggedDocument(words=['tas', 'rat', 'tent', 'tât', 'tas', 'riz', 'tant'], tags=None),\n",
              " TaggedDocument(words=['critiqu'], tags=None),\n",
              " TaggedDocument(words=['bon', 'tart', 'fruit', 'invit', 'amis', 'goût'], tags=None),\n",
              " TaggedDocument(words=['sav', 'utilis', 'cas', 'urgenc'], tags=None),\n",
              " TaggedDocument(words=['rencontr', 'second', 'tempêt', 'terribl', 'imprévu', 'beau', 'lac', 'rafal', 'vent', 'sortent', 'improv', 'gorg', 'montagn', 'plac', 'direct', 'oppos', 'luttent', 'eau'], tags=None),\n",
              " TaggedDocument(words=['pris', 'compt', 'exigent', 'nécessit', 'construir', 'nouvel', 'infrastructur'], tags=None),\n",
              " TaggedDocument(words=['plag', 'plein', 'marseil', 'tourist'], tags=None),\n",
              " TaggedDocument(words=['cicatric', 'profond', 'partag', 'figur', 'cheveux', 'cou', 'affreux', 'mutil', 'don', 'aspect', 'terribl'], tags=None),\n",
              " TaggedDocument(words=['avantag', 'solut', 'techniqu', 'séduis', 'trouv', 'larg', 'gamm', 'appliqu', 'domain', 'transport'], tags=None),\n",
              " TaggedDocument(words=['apprentissag', 'cod', 'larg', 'cultur', 'général', 'numer', 'écol', 'mesur', 'réclam', 'academ', 'scienc', 'soutenu', 'acteur', 'comptent', 'secteur', 'numer'], tags=None),\n",
              " TaggedDocument(words=['ciel', 'scrut', 'raison', 'ici', 'scientif'], tags=None),\n",
              " TaggedDocument(words=['question', 'été', 'pos', 'franc', 'emblémat', 'privatis', 'thomson', 'multimédi', 'milieu', 'anné', '1990'], tags=None),\n",
              " TaggedDocument(words=['bon', 'beaucoup'], tags=None),\n",
              " TaggedDocument(words=['cher', 'luc', 'écris', 'grand', 'parent', 'aigl', 'normand', 'pass', 'sup', 'vacanc', 'semain'], tags=None),\n",
              " TaggedDocument(words=['grand', 'port', 'liverpool', 'hambourg', 'bordeau', 'marseil', 'centr', 'culturel', 'intellectuel'], tags=None),\n",
              " TaggedDocument(words=['prèpar', 'prend', 'pet', 'déjeun', 'ensuit'], tags=None),\n",
              " TaggedDocument(words=['végétarien', 'fin', 'chang', 'régim', 'avis', 'plat', 'végétarien', 'goût', 'fad'], tags=None),\n",
              " TaggedDocument(words=['mid', 'promen', 'tuiler', 'parad', 'verdur', 'coeur', 'capital'], tags=None),\n",
              " TaggedDocument(words=['décen', 'our', 'asiat', 'quas', 'disparu', 'raison', 'attrait', 'représentent', 'patt', 'gastronom', 'vésicul', 'biliair', 'réput', 'aphrodisiaqu'], tags=None),\n",
              " TaggedDocument(words=['tient', 'cour', 'samed', 'prochain'], tags=None),\n",
              " TaggedDocument(words=['derni', 'étud', 'imager', 'cérébral', 'confirment', 'bien', 'différent', 'non', 'capac', 'fonction', 'cerveau', 'homm', 'femm', 'fonction', 'centr', 'intérêt'], tags=None),\n",
              " TaggedDocument(words=['discipl', 'enthousiast', 'jean', 'jacqu', 'rousseau', 'tendress', 'amant', 'natur', 'champ', 'bois', 'bêt'], tags=None),\n",
              " TaggedDocument(words=['devenu', 'curios', 'parisien', 'établ', 'attir', 'foul', 'venus', 'observ', 'spectacl', 'traver', 'épais', 'rideau'], tags=None),\n",
              " TaggedDocument(words=['insistent', 'animal', 'soient', 'chass', 'méthod', 'traditionnel', 'exclut', 'emploi', 'fusil', 'haut', 'port', 'bateau', 'mécanis'], tags=None),\n",
              " TaggedDocument(words=['grand', 'coup', 'rouleau', 'mont', 'immens', 'perch', 'membr', 'greenpeac', 'partiel', 'repeint', 'vert', 'avion', 'air', 'franc', 'station', 'aéroport', 'paris', 'charl', 'gaull', 'roissy', 'vendred', 'matin'], tags=None),\n",
              " TaggedDocument(words=['derni', 'jour', 'écol'], tags=None),\n",
              " TaggedDocument(words=['prépar', 'rep', 'cuisin'], tags=None),\n",
              " TaggedDocument(words=['terrain', 'conflictuel', 'existent', 'aventur', 'aut', 'exalt'], tags=None),\n",
              " TaggedDocument(words=['fus', 'lourd', 'tromp', 'calcul'], tags=None),\n",
              " TaggedDocument(words=['activ', 'dépend', 'présuppos', 'rapport', 'subordin', 'emploi', 'soumet', 'instruct', 'employeur'], tags=None),\n",
              " TaggedDocument(words=['resultat', 'experimental', 'montrent', 'micro', 'beton', 'defin', 'état', 'caracterist', 'separ', 'typ', 'comport', 'rheolog'], tags=None),\n",
              " TaggedDocument(words=['cru', 'comprendr'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'interdisent', 'conscienc', 'fili', 'dit', 'masculin', 'scienc', 'convaincu', 'hauteur'], tags=None),\n",
              " TaggedDocument(words=['aucun', 'nouvel', 'départ'], tags=None),\n",
              " TaggedDocument(words=['objet', 'berg', 'jet', 'cou', 'dragon'], tags=None),\n",
              " TaggedDocument(words=['cherch', 'chos', 'prec'], tags=None),\n",
              " TaggedDocument(words=['bien', 'attir', 'scientif', 'mesur', 'défaut', 'dirig', 'polit', 'craign', 'respons', 'jurid', 'répons', 'national', 'lent', 'indécis', 'utilis', 'réexamin', 'uniqu', 'utilis', 'derni', 'recour'], tags=None),\n",
              " TaggedDocument(words=['concentr', 'anné', 'résultat', 'scolair', 'enfant', 'parent', 'prêt', 'bain', 'mer', 'soleil', 'délav', 'tabl', 'multipl', 'parf', 'indiqu', 'théorem', 'géometr', 'cher', 'acquis'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'égar', 'jour', 'vivr', 'évoqu', 'aussitôt', 'désir', 'plaisir', 'particuli', 'interrompt', 'rêv', 'étion', 'train', 'fair', 'plac', 'tôt', 'tard', 'tour', 'feuillet', 'détach', 'chapitr', 'calendri', 'interpol', 'bonheur', 'bientôt', 'phénomen', 'naturel', 'confort', 'sant', 'tir', 'bénéfic', 'accidentel', 'minc', 'jour', 'scienc', 'empar', 'produis', 'volont', 'remet', 'main', 'possibil', 'apparit', 'soustrait', 'tutel', 'dispens', 'agrément', 'hasard', 'product', 'rêv', 'atlant', 'ital', 'cess', 'soumis', 'uniqu', 'chang', 'saison', 'temp'], tags=None),\n",
              " TaggedDocument(words=['gain', 'product', 'aliment', 'affect', '840', 'million', 'person'], tags=None),\n",
              " TaggedDocument(words=['offre', 'meilleur', 'guid', 'grav', 'montagn', 'épanou'], tags=None),\n",
              " TaggedDocument(words=['quitt', 'aller', 'travaill', 'bon', 'visit'], tags=None),\n",
              " TaggedDocument(words=['langu', 'moyen', 'privilégi', 'commun', 'humain', 'incarnent', 'vision', 'mond', 'locuteur', 'imaginair', 'façon', 'véhicul', 'savoir'], tags=None),\n",
              " TaggedDocument(words=['perspect', 'quas', 'inconcev', 'congres', 'divis'], tags=None),\n",
              " TaggedDocument(words=['fier', 'temp', 'temp', 'bagarrent', 'veut', 'patrici', 'bagarr', 'agnes', 'valer', 'michel', 'aud', 'rit'], tags=None),\n",
              " TaggedDocument(words=['emus', 'journal', 'sugger', 'idé', 'célebr', 'mer', 'egypt', 'fêt', 'propag', 'pay', 'arab'], tags=None),\n",
              " TaggedDocument(words=['rythm', 'vingtain', 'terrain', 'football', 'minut'], tags=None),\n",
              " TaggedDocument(words=['sert', 'rien'], tags=None),\n",
              " TaggedDocument(words=['préfer', 'somm', 'arrond'], tags=None),\n",
              " TaggedDocument(words=['problem', 'tabl'], tags=None),\n",
              " TaggedDocument(words=['laiss', 'beaucoup', 'parl', 'franc', 'oubl', 'franc', 'impos', 'langu', 'administr', 'xvi', 'siecl', 'trait', 'viller', 'cotteret'], tags=None),\n",
              " TaggedDocument(words=['parallel', 'inhum', 'animal', 'li', 'sacr', 'rit', 'magiqu', 'exist', 'égypt', 'antiqu', 'simpl', 'tomb', 'chien', 'chat', 'apprivois'], tags=None),\n",
              " TaggedDocument(words=['faux'], tags=None),\n",
              " TaggedDocument(words=['vrai', 'bienvenu'], tags=None),\n",
              " TaggedDocument(words=['maison', 'aller', 'pied', 'agréabl'], tags=None),\n",
              " TaggedDocument(words=['5', 'an', 'famill', 'déménag', 'sud', 'franc'], tags=None),\n",
              " TaggedDocument(words=['rentr', 'heur'], tags=None),\n",
              " TaggedDocument(words=['plupart', 'temp', 'ête', 'maison', 'suit', 'intervent', 'beaucoup', 'facil'], tags=None),\n",
              " TaggedDocument(words=['maréchal', 'ferr', 'coch', 'dû', 'reconvert'], tags=None),\n",
              " TaggedDocument(words=['etud', 'transmiss', 'greffag', 'multipl', 'plant', 'hot', 'pouvoir', 'pathogen', 'capacit', 'souch', 'premun'], tags=None),\n",
              " TaggedDocument(words=['pai', 'compensatoir', 'exempl', 'impôt', 'tax', 'li', 'transport', 'vers', 'usager', 'transport', 'pouvoir', 'public', 'pai', 'voyageur', 'entrepris', 'transport', 'form', 'billet', 'abon', 'indemnis', 'vers', 'pouvoir', 'public', 'entrepris', 'transport'], tags=None),\n",
              " TaggedDocument(words=['jul', 'lausann', 'mois'], tags=None),\n",
              " TaggedDocument(words=['impliqu', 'vi', 'social', 'colleg'], tags=None),\n",
              " TaggedDocument(words=['paris', 'vill', 'tourist', 'mond', 'parv', 'darn', 'fil', 'tourist', 'allong', 'guichet'], tags=None),\n",
              " TaggedDocument(words=['remarqu', 'irrégular', 'procédur'], tags=None),\n",
              " TaggedDocument(words=['calm', 'pourt', 'dur'], tags=None),\n",
              " TaggedDocument(words=['nuit', 'dieu', 'perm', 'rêv'], tags=None),\n",
              " TaggedDocument(words=['vien'], tags=None),\n",
              " TaggedDocument(words=['fair', 'fair'], tags=None),\n",
              " TaggedDocument(words=['bon', 'baiser', 'réunion', 'passon', 'jour', 'vacanc'], tags=None),\n",
              " TaggedDocument(words=['paradoxal', 'oblig', 'réglementair', 'strict', 'facilitent', 'développ', 'traitanc', 'renforc', 'conséquent', 'dynam', 'économ'], tags=None),\n",
              " TaggedDocument(words=['ser', 'documentair', 'volet', 'retrac', 'siecl', 'histoir', 'chin', 'détaill', 'ascens', 'statut', 'superpuiss'], tags=None),\n",
              " TaggedDocument(words=['militair', 'saluent', 'président', 'républ', 'gouvern', 'principal', 'autor', 'état', 'corp', 'diplomat', 'personnal', 'polit', 'étranger', 'invit', 'occas'], tags=None),\n",
              " TaggedDocument(words=['1999', 'propos', 'deven', 'chef', 'servic', 'polit'], tags=None),\n",
              " TaggedDocument(words=['expérient', 'put', 'men', 'bien', 'bien', 'mérit', 'concevoir', 'réaumur', 'biolog', 'tent', 'prolong', 'vi', 'mammifer', 'impos', 'torpeur', 'artificiel', 'entretenu'], tags=None),\n",
              " TaggedDocument(words=['don', 'heur', 'déjeun', 'dat', 'adress', 'appart'], tags=None),\n",
              " TaggedDocument(words=['tand', 'rois', 'chant', 'deum', 'camp', 'prit', 'part', 'aller', 'raison', 'ailleur', 'effet', 'caus'], tags=None),\n",
              " TaggedDocument(words=['pass', 'press', 'attardent', 'facil', 'devantur', 'rayon'], tags=None),\n",
              " TaggedDocument(words=['chant', 'matin', 'douch', 'objet', 'prier', 'priorit', 'numéro'], tags=None),\n",
              " TaggedDocument(words=['défenseur', 'projet', 'permettr', 'adapt', 'pratiqu', 'scolair', 'mond', 'professionnel'], tags=None),\n",
              " TaggedDocument(words=['ête', 'nord', 'nowr', 'trouv', 'refug', 'feu', 'arriv'], tags=None),\n",
              " TaggedDocument(words=['mard', 'ressembl', 'lund', 'activité', 'aprè', 'écol', 'david', 'rentr', 'fair', 'devoir', 'repos'], tags=None),\n",
              " TaggedDocument(words=['rencontr', 'souven', 'confus', 'prec'], tags=None),\n",
              " TaggedDocument(words=['grand', 'puissanc', 'collect', 'respons', 'paix', 'repos', 'europ', 'concert', 'permanent', 'regl', 'problem', 'évit', 'débouchent', 'guerr', 'généralis'], tags=None),\n",
              " TaggedDocument(words=['pur', 'subject', 'objectiv', 'devient', 'langag', 'templ', 'fêt', 'individu'], tags=None),\n",
              " TaggedDocument(words=['écouton', 'musiqu'], tags=None),\n",
              " TaggedDocument(words=['départ', 'cheff', 'dev', 'travers', 'atlant', 'réjou', 'franc', 'aiment', 'femm', 'mûr', 'preuv', 'président', 'jeun', 'sexy', 'épous', 'prof'], tags=None),\n",
              " TaggedDocument(words=['public', 'découvr', 'magazin', 'hebdomadair', 'premi', 'nouvel', 'met', 'scen', 'fameux', 'détect', 'fidel', 'watson'], tags=None),\n",
              " TaggedDocument(words=['ailleur', 'yoland', 'habit', 'paris', 'expliqu', 'quotidien', 'devenu', 'difficil', 'raison', 'locat', 'saisonni', 'arriv', 'départ', 'heur', 'journ', 'fêt', 'nuit', 'group', 'tourist', 'envah', 'hall', 'immeubl', 'valis'], tags=None),\n",
              " TaggedDocument(words=['domain', 'publiqu', 'vendr', 'espac', 'publicitair'], tags=None),\n",
              " TaggedDocument(words=['veux', 'montr', 'lign', 'cod'], tags=None),\n",
              " TaggedDocument(words=['révolu', 'français', 'étend', 'system', 'recrut', 'ensembl', 'administr', 'techniqu', 'suscit', 'création', 'écol', 'polytechn', '1794'], tags=None),\n",
              " TaggedDocument(words=['exempl', 'chois', 'pantalon', 'rob', 'allez', 'franco', 'haut'], tags=None),\n",
              " TaggedDocument(words=['arme', 'abandon', 'march', 'silenci', 'main', 'ball'], tags=None),\n",
              " TaggedDocument(words=['vrai', 'dû', 'beaucoup', 'insist', 'chois', 'rapport', 'monsieur'], tags=None),\n",
              " TaggedDocument(words=['inuit', 'espèrent', 'pouvoir', 'appui', 'rapport', 'rem', 'septembr', '2004', 'pay', 'conseil', 'arctiqu'], tags=None),\n",
              " TaggedDocument(words=['voit', 'grand', 'mass', 'ouvri', 'spécialis', 'informat', 'alimentent', 'tuyal', 'inform', 'rapid'], tags=None),\n",
              " TaggedDocument(words=['pierr', 'jeun', 'garçon', '14', 'an'], tags=None),\n",
              " TaggedDocument(words=['gagn', 'argent'], tags=None),\n",
              " TaggedDocument(words=['jour', 'fix', 'lendemain', 'époqu', 'invari', 'déclar', 'posit', 'lendemain', 'écoul', 'teil'], tags=None),\n",
              " TaggedDocument(words=['mar', 'aim', 'beaucoup', 'mer'], tags=None),\n",
              " TaggedDocument(words=['lund', 'rest', 'bibliothequ', 'fermetur'], tags=None),\n",
              " TaggedDocument(words=['loir', 'vélo', '900', 'kilometr', 'pist', 'aménag', 'long', 'fleuv'], tags=None),\n",
              " TaggedDocument(words=['aim', 'bien', 'film', '1964', 'aim', 'bien', 'comed'], tags=None),\n",
              " TaggedDocument(words=['prêt'], tags=None),\n",
              " TaggedDocument(words=['enlev', 'gard', 'chaussur', 'march', 'bord', 'eau'], tags=None),\n",
              " TaggedDocument(words=['fill', 'français', 'an'], tags=None),\n",
              " TaggedDocument(words=['form', 'histoir', 'art', 'âge', '30', 'an'], tags=None),\n",
              " TaggedDocument(words=['monsieur', 'helmut', 'kohl', 'don', 'priorit', 'allemand'], tags=None),\n",
              " TaggedDocument(words=['chocolat', 'coul', 'form', 'oeuf', 'lapin', 'poul', 'dispers', 'jardin', 'retrouv', 'jeun', 'chass', 'oeuf'], tags=None),\n",
              " TaggedDocument(words=['réduit', 'divers', 'planet'], tags=None),\n",
              " TaggedDocument(words=['lle', 'vient', 'lanc', 'consult', 'publiqu', 'sujet'], tags=None),\n",
              " TaggedDocument(words=['consider', 'arrier', 'pai', 'impai', 'retard', 'pai', 'cas', 'loi', 'intérêt', 'hypothécair', 'log', 'principal', 'factur', 'eau', 'électr', 'gaz', 'chauffag', 'prim', 'assur', 'malad', 'rembours', 'crédit', 'impôt'], tags=None),\n",
              " TaggedDocument(words=['génial', 'puiss', 'rencontr'], tags=None),\n",
              " TaggedDocument(words=['tableau', 'fontan', 'collect', 'mus', '2003', 'vient', 'dérob'], tags=None),\n",
              " TaggedDocument(words=['temp', 'dur', 'mission', 'homm', 'envoi', 'forêt'], tags=None),\n",
              " TaggedDocument(words=['achet', 'franc', 'devient', 'acte', 'écolog', 'achet', 'produit', 'franc', 'entendr', 'achet', 'produit', 'été', 'fabriqu', 'bout', 'mond', 'fair', 'baiss', 'pollut', 'limit', 'transport', 'marchandis', 'diminu', 'empreint', 'carbon'], tags=None),\n",
              " TaggedDocument(words=['aller', 'vérifi'], tags=None),\n",
              " TaggedDocument(words=['demeur', 'an', 'maison', 'pleur', 'mer', 'fut', 'mis', 'sacr', 'coeur'], tags=None),\n",
              " TaggedDocument(words=['pap', 'voyag', 'demain'], tags=None),\n",
              " TaggedDocument(words=['ven', 'délass', 'beau', 'art', 'inquiétud', 'vent', 'oubli', 'point', 'affair', 'caus', 'coton', 'indigo'], tags=None),\n",
              " TaggedDocument(words=['sais', 'con', 'paris', 'propos', 'ven', 'pass', 'jour'], tags=None),\n",
              " TaggedDocument(words=['essai', 'comprendr', 'écout'], tags=None),\n",
              " TaggedDocument(words=['utilis', 'beaucoup', 'rar'], tags=None),\n",
              " TaggedDocument(words=['mid', 'amis', 'cinem'], tags=None),\n",
              " TaggedDocument(words=['temp', 'cours', 'jour', 'heur', 'minut', 'second'], tags=None),\n",
              " TaggedDocument(words=['voi', 'loin', 'petit', 'mass', 'sombr', 'roch', 'entour', 'halo', 'aveugl', 'lumi', 'poussi', 'mer'], tags=None),\n",
              " TaggedDocument(words=['pens', 'conséquent', 'authent', 'liber', 'homm', 'interact', 'moral', 'social', 'polit'], tags=None),\n",
              " TaggedDocument(words=['conseil', 'march', 'jour'], tags=None),\n",
              " TaggedDocument(words=['précis', 'part', 'vacanc', 'demain'], tags=None),\n",
              " TaggedDocument(words=['programm', 'organis', 'blind', 'test', 'karaok', 'class', 'artist', 'francophon', 'anné', '1960', 'aujourd'], tags=None),\n",
              " TaggedDocument(words=['euss', 'éclair', 'bleuâtr', 'pareil', 'épar', 'non', 'suiv', 'tonnerr', 'labourent', 'firm', 'nuag', 'chaud', 'nuit', 'été'], tags=None),\n",
              " TaggedDocument(words=['viennent', 'bouch', 'menton'], tags=None),\n",
              " TaggedDocument(words=['eut', 'fin', 'intervent', 'éloqu', 'part', 'fier'], tags=None),\n",
              " TaggedDocument(words=['errais', 'cess', 'port', 'ellénor'], tags=None),\n",
              " TaggedDocument(words=['effect', 'état', 'esprit', 'moment', 'expérient', 'fil', 'temp', 'sais', 'veux', 'cas'], tags=None),\n",
              " TaggedDocument(words=['promen', 'bois', 'admir', 'couleur', 'chaleur', 'roug', 'orang', 'jaun'], tags=None),\n",
              " TaggedDocument(words=['appel', 'demain'], tags=None),\n",
              " TaggedDocument(words=['pourr', 'ven', 'demain', 'fair', 'vélo'], tags=None),\n",
              " TaggedDocument(words=['aucun', 'trac', 'braqueur', 'banqu'], tags=None),\n",
              " TaggedDocument(words=['bonjour', 'mademoisel', 'ser'], tags=None),\n",
              " TaggedDocument(words=['garçon', 'aur', 'déçu', 'parent', 'avi', 'échou'], tags=None),\n",
              " TaggedDocument(words=['faut', 'plant', 'arbre', 'pieg', 'rejet', 'li', 'voyag', 'aller', 'avion', 'milan', 'new', 'york'], tags=None),\n",
              " TaggedDocument(words=['voudr', 'remerci', 'mer', 'dois'], tags=None),\n",
              " TaggedDocument(words=['but', 'interdir', 'jeun', 'quarti', 'sort', 'minuit', '22', 'heur', '6', 'heur', 'matin', 'accompagn', 'adult'], tags=None),\n",
              " TaggedDocument(words=['voulion', 'ascenseur', 'voisin', 'lou', 'appart', 'voul', 'absolu', 'attir', 'tourist'], tags=None),\n",
              " TaggedDocument(words=['anné', 'enregistr', 'augment', 'violenc', 'jeun'], tags=None),\n",
              " TaggedDocument(words=['max', 'ira', 'univers', 'anné', 'prochain'], tags=None),\n",
              " TaggedDocument(words=['derni', 'géner', 'amplifi', 'societ', 'individual', 'ambivalent'], tags=None),\n",
              " TaggedDocument(words=['ser', 'real', 'human', 'homm', 'tombent', 'amour', 'robot'], tags=None),\n",
              " TaggedDocument(words=['étoff', 'viv', 'passion', 'trottoir', 'dentel', 'frisson', 'retomb', 'cach', 'profondeur', 'magasin', 'air', 'troubl', 'myster', 'piec', 'drap', 'épaiss', 'carr', 'resp', 'souffl', 'halein', 'tentatric', 'tand', 'paletot', 'cambr', 'davantag', 'mannequin', 'pren', 'âme', 'grand', 'manteau', 'velour', 'gonfl', 'soupl', 'tied', 'épaul', 'chair', 'batt', 'gorg', 'frem', 'rein'], tags=None),\n",
              " TaggedDocument(words=['crois', 'sav', 'christian', 'malad', 'connaisson', 'instant', 'dur', 'absenc'], tags=None),\n",
              " TaggedDocument(words=['port', 'pantalon'], tags=None),\n",
              " TaggedDocument(words=['jean', 'jour', 'plag'], tags=None),\n",
              " TaggedDocument(words=['départ', 'mlle', 'swann', 'ôtant', 'chanc', 'terribl', 'voir', 'apparaîtr', 'allé', 'connu', 'mépris', 'petit', 'fill', 'privilégi', 'bergott', 'ami', 'allait', 'visit', 'cathédral', 'rend', 'contempl', 'tansonvill', 'indifférent', 'fois', 'permis', 'sembl', 'contrair', 'ajout', 'propriet', 'yeux', 'grand', 'per', 'per', 'commod', 'agrément', 'passag', 'excurs', 'pay', 'montagn', 'absenc', 'nuag', 'journ', 'exceptionnel', 'propic', 'promenad', 'côt', 'aur', 'voulu', 'calcul', 'fussent', 'déjou', 'miracl', 'fît', 'apparaîtr', 'mlle', 'swann', 'per', 'aurion', 'temp', 'évit', 'serion', 'oblig', 'fair', 'connaiss'], tags=None),\n",
              " TaggedDocument(words=['march', 'herb', 'tribunal'], tags=None),\n",
              " TaggedDocument(words=['rêv', 'princ'], tags=None),\n",
              " TaggedDocument(words=['oui', 'bien', 'sûr'], tags=None),\n",
              " TaggedDocument(words=['soir', 'regard', 'photos', 'album', 'familial', 'souviendron', 'moment', 'agréabl'], tags=None),\n",
              " TaggedDocument(words=['societ', 'embauch', 'développeur', 'sayn', 'an', 'derni', 'compt', 'bien', 'renouvel', 'expérient', '2019'], tags=None),\n",
              " TaggedDocument(words=['observ', 'microscop', 'rével', 'différent', 'échel', 'cellulair'], tags=None),\n",
              " TaggedDocument(words=['habitud', 'compagn', 'quelqu', 'heur', 'jour', 'reconnaît', 'chroniqu', 'culinair'], tags=None),\n",
              " TaggedDocument(words=['bienfaiteur', 'apport', 'aid', 'général', 'don', 'argent'], tags=None),\n",
              " TaggedDocument(words=['net', 'tendanc', 'consider', 'choix', 'vi', 'personnel', 'recevoir', 'aucun', 'justif', 'approb', 'social'], tags=None),\n",
              " TaggedDocument(words=['marquis', 'repr', 'doux', 'constat', 'protecteur', 'massif', 'pelous', 'écout', 'bonhom', 'song', 'contredir', 'gard', 'inoffens', 'fourreau', 'épé', 'air', 'instrument', 'jardinag', 'attribut', 'horticol'], tags=None),\n",
              " TaggedDocument(words=['fis', 'mouv', 'éloign'], tags=None),\n",
              " TaggedDocument(words=['répond', 'hésit'], tags=None),\n",
              " TaggedDocument(words=['arriv', 'faut', 'rest', 'motiv'], tags=None),\n",
              " TaggedDocument(words=['comt', 'pietran', 'expos', 'vi', 'sauv', 'ministr', 'fut', 'tu', 'coup', 'paraplui', 'supplic', 'dur', 'heur'], tags=None),\n",
              " TaggedDocument(words=['droit', 'tabl', 'fauteuil', 'fauteuil', 'blouson'], tags=None),\n",
              " TaggedDocument(words=['divorc', 'grimpent', 'flech'], tags=None),\n",
              " TaggedDocument(words=['jeun', 'fill', 'décourag', 'manqu', 'offre', 'créneau', 'horair', 'attrai', 'not', 'inse'], tags=None),\n",
              " TaggedDocument(words=['conscienc', 'religi', 'conscienc', 'moral', 'malheur'], tags=None),\n",
              " TaggedDocument(words=['point', 'caus', 'répond', 'modest', 'candid', 'enchaîn', 'nécessair', 'arrang', 'mieux'], tags=None),\n",
              " TaggedDocument(words=['cinéast', 'adapt', 'livr', 'cinem', 'forc', 'prendr', 'distanc', 'rapport', 'livr'], tags=None),\n",
              " TaggedDocument(words=['plag'], tags=None),\n",
              " TaggedDocument(words=['ren', 'jacob', 'évoqu', 'enfanc', 'genev', 'suiss', 'frer', 'per', 'astrophysicien', 'cern', 'aim', 'dessin', 'flip', 'book', 'personnag', 'cartoon', 'mer', 'anné', 'pass', 'foi', 'repr', 'étud', 'deven', 'psychothérapeut', 'enfant'], tags=None),\n",
              " TaggedDocument(words=['cas', 'avis', 'avocat', 'florentin', 'honor', 'alessandro', 'travers', 'invit', 'scientif', 'représent', 'intérêt', 'ancêtr', 'examen', 'fauss', 'requêt', 'révis', 'proces', 'dant'], tags=None),\n",
              " TaggedDocument(words=['utilis'], tags=None),\n",
              " TaggedDocument(words=['dimach', 'fêt', 'mer', 'franc'], tags=None),\n",
              " TaggedDocument(words=['petit', 'jou', 'dans', 'autour', 'feu', 'joi'], tags=None),\n",
              " TaggedDocument(words=['inégal', 'sex', 'frein', 'acces', 'étud', 'scientif'], tags=None),\n",
              " TaggedDocument(words=['mieux', 'maîtris', 'sonlangag', 'septembr', 'juin', 'écrivain', 'yakriv', 'propos', 'approch', 'personnel', 'quin', 'fin', 'séduir', 'auteur', 'lupour', 'grammair', 'impertinentepropos', 'jeux', 'lir', 'vit', 'retz', 'fair', 'aimerl', 'grammair', 'récalcitr', 'résisteen', 'plais', 'schtroumpf', 'text', 'remplac', 'verb', 'actionet', 'particip', 'pass', 'verb', 'schtroump', 'fer', 'correct', 'accord', 'bien', 'sûr', 'refu', 'trouv', 'rapid', 'motl', 'long', 'pet', 'text', 'identifi', 'desmot', 'cach'], tags=None),\n",
              " TaggedDocument(words=['fiabl', 'permet', 'exprim', 'distinct', 'vis', 'vis', 'mass', 'populair', 'ressent', 'fac', 'societ', 'plein', 'promess', 'contraint'], tags=None),\n",
              " TaggedDocument(words=['profess', 'padou', 'princip', 'philosoph', 'fagot', 'découvert', 'scienc', 'danger', 'pourront', 'bien', 'fin', 'brouill', 'églis'], tags=None),\n",
              " TaggedDocument(words=['agent', 'marqu', 'saut', 'digu', 'napoléon', 'ven', 'débarqu', 'golf', 'juan'], tags=None),\n",
              " TaggedDocument(words=['agiss', 'francis', 'républ', 'fair', 'sort', 'petit', 'franc', 'franc'], tags=None),\n",
              " TaggedDocument(words=['cour', 'venu', 'asseoir', 'côt'], tags=None),\n",
              " TaggedDocument(words=['accapar', 'affair', 'publiqu', 'avantag'], tags=None),\n",
              " TaggedDocument(words=['mis', 'évident', 'rôl', 'clé', 'aliment', 'apparit', 'trait', 'troubl', 'mental', 'dépress', 'troubl', 'anxieux', 'schizophren', 'autism'], tags=None),\n",
              " TaggedDocument(words=['mond', 'savoir', 'vus', 'nacel', 'rou', 'forain', 'histoir', 'ramen', 'scintill', 'liss', 'grand', 'boucl', 'model', 'inconscient', 'expospher', 'travers', 'vieil', 'décen', 'continent'], tags=None),\n",
              " TaggedDocument(words=['mar', 'soph', 'germain', 'origin', 'théor', 'scientif', 'reconnu'], tags=None),\n",
              " TaggedDocument(words=['côt', 'chassent', 'phoqu', 'balein', 'tand', 'intérieur', 'terr', 'élèvent', 'ren'], tags=None),\n",
              " TaggedDocument(words=['aim', 'promen', 'amis', 'rêv', 'voyag', 'pourrion', 'fair', 'ensembl'], tags=None),\n",
              " TaggedDocument(words=['petit', 'tradit'], tags=None),\n",
              " TaggedDocument(words=['pris', '100', 'euros'], tags=None),\n",
              " TaggedDocument(words=['itinérair', 'don', 'pierr', 'ami', 'franc'], tags=None),\n",
              " TaggedDocument(words=['disponibil', 'servic', 'obtenu', 'dimension', 'appropri', 'redond', 'infrastructur', 'gestion', 'opérationnel', 'mainten', 'efficac', 'infrastructur', 'ressourc', 'servic'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'clé'], tags=None),\n",
              " TaggedDocument(words=['chos', 'fait', 'revint', 'trist', 'château', 'griant'], tags=None),\n",
              " TaggedDocument(words=['moment'], tags=None),\n",
              " TaggedDocument(words=['forêt', 'don', 'bois', 'gibi'], tags=None),\n",
              " TaggedDocument(words=['accept', 'robot', 'évolu', 'fil', 'futur', 'géner', 'débouch', 'attach'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'contraint', 'spécial', 'éduc', 'réflexion', 'doulour', 'embarrass'], tags=None),\n",
              " TaggedDocument(words=['saison', 'serpent', 'dorm', 'terr'], tags=None),\n",
              " TaggedDocument(words=['protocol', 'expérimental', 'métaphys', 'object', 'prouv', 'existent', 'libert', 'indifférent', 'propr', 'humain'], tags=None),\n",
              " TaggedDocument(words=['version', 'film'], tags=None),\n",
              " TaggedDocument(words=['contrair', 'aîn', 'part', 'retrait', 'usé', 'travail', 'problem', 'sant', 'sexagénair', 'aujourd', 'pein', 'mech', 'gris'], tags=None),\n",
              " TaggedDocument(words=['subit', 'été', 'pâmoison', 'pris', 'vision', 'entré', 'soudain', 'gérard'], tags=None),\n",
              " TaggedDocument(words=['loin', 'forc', 'manifest', 'désobéiss', 'sain', 'réaction', 'indépend'], tags=None),\n",
              " TaggedDocument(words=['chantion', 'ensembl', 'mer', 'assis', 'piano', 'main', 'coeur', 'tendu', 'barricad', 'regard', 'yeux', 'venion', 'arme', 'citoyen', 'mer', 'abatt', 'main', 'violenc', 'clavi', 'brand', 'poing', 'air', 'menac'], tags=None),\n",
              " TaggedDocument(words=['mar', 'professeur', 'anglais', 'écol', 'trouv', '20', 'kilometr', 'maison'], tags=None),\n",
              " TaggedDocument(words=['homm', 'exprim', 'aut', 'hain', 'imagin', 'amour', 'pouvon', 'exprim', 'ensembl'], tags=None),\n",
              " TaggedDocument(words=['gris', 'mélang', 'blanc', 'noir'], tags=None),\n",
              " TaggedDocument(words=['parl', 'bien', 'anglais'], tags=None),\n",
              " TaggedDocument(words=['royaum', 'europ', 'voyag', 'capital', 'capital', 'partag', 'fatigu', 'orgueil', 'ramass', 'fleur', 'jet', 'brod', 'costum', 'soir', 'fond', 'log', 'grill', 'treil', 'eût', 'recueil', 'bé', 'expans', 'âme', 'chant', 'scen', 'jou', 'regard'], tags=None),\n",
              " TaggedDocument(words=['grand', 'part', 'jour', 'attend', 'vain', 'répons'], tags=None),\n",
              " TaggedDocument(words=['sheil', 'watt', 'clouti', 'président', 'conférent', 'circumpolair', 'inuit', 'déclar', 'droit', '155', '000', 'inuit', 'vivent', 'canad', 'russ', 'groenland'], tags=None),\n",
              " TaggedDocument(words=['repr', 'vi', 'habituel', 'angoiss', 'éprouv', 'commenc', 'dissip', 'lorsqu', 'bout', 'mois', 'p', 'fit', 'avert', 'ellénor', 'dev', 'arriv', 'soir'], tags=None),\n",
              " TaggedDocument(words=['pass', 'bon', 'soir'], tags=None),\n",
              " TaggedDocument(words=['cinem'], tags=None),\n",
              " TaggedDocument(words=['taill', 'vigour', 'pris', 'pourpoint', 'couleur', 'brun', 'pet', 'poignard', 'cisel', 'batt', 'cuiss', 'gauch', 'roul', 'regard', 'langour', 'découvr', 'dent', 'blanch'], tags=None),\n",
              " TaggedDocument(words=['recrut', 'effectuent', 'essentiel', 'part', 'criter', 'li', 'voix', 'bon', 'contact', 'express', 'oral'], tags=None),\n",
              " TaggedDocument(words=['héros', 'meurt', 'fin', 'film'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'différent', 'développ', 'langag', 'enfant', 'bilingu', 'enfant', 'monolingu'], tags=None),\n",
              " TaggedDocument(words=['second', 'copain', 'fit', 'étud', 'commerc'], tags=None),\n",
              " TaggedDocument(words=['vit', 'ralent'], tags=None),\n",
              " TaggedDocument(words=['femm', 'plein', 'vertus'], tags=None),\n",
              " TaggedDocument(words=['dev', 'assist', 'mess', 'particip', 'fêt', 'collect', 'réunion', 'familial'], tags=None),\n",
              " TaggedDocument(words=['class', 'interd', 'fum'], tags=None),\n",
              " TaggedDocument(words=['ange', 'apparaît', 'fois', 'conseil', 'azaël'], tags=None),\n",
              " TaggedDocument(words=['aujourd'], tags=None),\n",
              " TaggedDocument(words=['soir', 'lis', 'dor', 'divan'], tags=None),\n",
              " TaggedDocument(words=['richard', 'castel', 'xix', 'siecl', 'usag', 'machin', 'robot', 'conduit', 'licenci', 'disparit', 'méti', 'bien', 'processus', 'été', 'ralent', 'possibil', 'main', 'oeuvr', 'économ', 'ancien', 'pay', 'industrialis'], tags=None),\n",
              " TaggedDocument(words=['derni', 'moutur', 'text', 'résultat', 'comprom', 'sein', 'major', 'cop', 'pâlichon', 'projet', 'initial', 'magasin', 'pourront', 'ouvr', 'port', 'dimanch', 'an', 'lieu', 'aujourd'], tags=None),\n",
              " TaggedDocument(words=['derni', 'soir', 'réserv', 'tabl', 'restaur', 'romant', 'florenc', 'histoir', 'fin', 'séjour', 'beaut'], tags=None),\n",
              " TaggedDocument(words=['appel', 'albert', 'an'], tags=None),\n",
              " TaggedDocument(words=['histoir', 'touch', 'serv', 'plum', 'anna', 'gavald', 'pareil', 'simpl', 'émot', 'sent', 'fort'], tags=None),\n",
              " TaggedDocument(words=['ethiop', 'dat', 'fêt', 'mer', 'fix', 'détermin', 'avanc', 'dépend', 'fin', 'périod', 'plui'], tags=None),\n",
              " TaggedDocument(words=['auteur', 'exploit', 'terrain', 'erik', 'orsen', 'chevali', 'subjonct', 'sort', 'automn', '2004', 'mond', 'éducation', '°', '328', 'septembr', '2004'], tags=None),\n",
              " TaggedDocument(words=['secrétair', 'rest', 'bureau', 'journ'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'bruit', 'rien'], tags=None),\n",
              " TaggedDocument(words=['réun', 'pal', 'bûch', 'forg', 'tailleur', 'pierr', 'portent', 'lourd', 'fardeau', 'outil', 'pes', 'travaillent', 'carri', 'dressent', 'colon', 'édific', 'luttent', 'chos', 'inanim'], tags=None),\n",
              " TaggedDocument(words=['ici', 'chaud'], tags=None),\n",
              " TaggedDocument(words=['réalis', 'histoir', 'rêv'], tags=None),\n",
              " TaggedDocument(words=['résultat', 'indiquent', '6', 'mois', 'quart', 'enfant', 'dorm', 'jam', '6', 'heur', 'consécut', 'moiti', 'enfant', 'dorm', 'jam', '8', 'heur', 'consécut'], tags=None),\n",
              " TaggedDocument(words=['utop', 'mond', 'argent'], tags=None),\n",
              " TaggedDocument(words=['organis', 'greenpeac', 'reconnaissent', 'autochton', 'droit', 'prendr', 'animal', 'préserv', 'cultur'], tags=None),\n",
              " TaggedDocument(words=['paraiss', 'invraisembl'], tags=None),\n",
              " TaggedDocument(words=['économ', 'africain', 'capabl', 'fair', 'fac', 'det', 'mois', 'perdu', 'dis', 'point', 'croissanc', 'voir', 'récess'], tags=None),\n",
              " TaggedDocument(words=['xix', 'siecl', 'querel', 'fémin', 'devient', 'querel', 'partisan', 'conséquent', 'révolu', 'industriel', 'particip', 'femm', 'travail', 'producteur', 'moment', 'revend', 'fémin', 'sortent', 'domain', 'théoriqu', 'trouvent', 'bas', 'économ', 'adversair', 'deviennent', 'aut', 'agress', 'propriet', 'fonci', 'part', 'détrôn', 'bourgeois', 'accroch', 'vieil', 'moral', 'voit', 'solid', 'famill', 'gar', 'propriet', 'priv', 'réclam', 'femm', 'foi', 'aut', 'âprement', 'émancip', 'devient', 'vérit', 'menac', 'intérieur', 'class', 'ouvri', 'homm', 'essai', 'frein', 'liber', 'femm', 'apparaiss', 'danger', 'concurrent', 'aut', 'habitu', 'travaill', 'salair'], tags=None),\n",
              " TaggedDocument(words=['enfant', 'trait', 'fou'], tags=None),\n",
              " TaggedDocument(words=['bien', 'simpl', 'apprec', 'idé', 'tu', 'pauvr', 'animal', 'innocent'], tags=None),\n",
              " TaggedDocument(words=['quitt', 'pal', 'lou', 'chambr', 'étag', 'renvoi', 'femm', 'chambr', 'remplac', 'pauvr', 'vieil', 'ménag'], tags=None),\n",
              " TaggedDocument(words=['montr', 'exist', 'problem', 'souverainet', 'fuit', 'don', 'inférent', 'comport', 'traçag', 'concept', 'appliqu'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'peur'], tags=None),\n",
              " TaggedDocument(words=['autrefois', 'viv', 'retir', 'fui', 'societ', 'fatig', 'évit', 'éternel', 'convers', 'prolongent', 'précis', 'devr', 'jam', 'commenc'], tags=None),\n",
              " TaggedDocument(words=['préfer', 'mauv', 'couleur', 'temper', 'mélang', 'roug', 'chaleur', 'africain', 'froid', 'bleu', 'européen'], tags=None),\n",
              " TaggedDocument(words=['organ', 'intern', 'cerveau', 'log', 'têt'], tags=None),\n",
              " TaggedDocument(words=['meilleur', 'protect', 'vi', 'priv', 'conjugu', 'mesur', 'allant', 'sen', 'meilleur', 'gestion', 'risqu', 'sécur', 'numer', 'pourr', 'contribu', 'promouvoir', 'confianc'], tags=None),\n",
              " TaggedDocument(words=['pens', 'complex', 'rel', 'chos', 'sépar'], tags=None),\n",
              " TaggedDocument(words=['jour', 'féri', 'jour', 'travaill'], tags=None),\n",
              " TaggedDocument(words=['étudient', 'mani', 'assidu', 'desoin', 'redoubl'], tags=None),\n",
              " TaggedDocument(words=['an', 'jean', 'pass', 'vacanc', 'grand', 'hôtel', 'sud', 'franc'], tags=None),\n",
              " TaggedDocument(words=['plupart', 'habit', 'saluent', 'loi', 'protect', 'environ', 'commerc', 'inquiètent', 'magasin', 'bricolag', 'produit', 'trop', 'larg', 'trop', 'lourd', 'sac', 'papi'], tags=None),\n",
              " TaggedDocument(words=['cruel', 'sexuel', 'dou', 'capabl', 'fair', 'souffr', 'don', 'joi', 'tréfond'], tags=None),\n",
              " TaggedDocument(words=['mond', 'anglais', 'londr', 'paris'], tags=None),\n",
              " TaggedDocument(words=['entend', 'guer', 'cultur', 'indien', 'mont', 'cheval', 'lieu', 'envoi', 'labour', 'buv', 'cidr', 'bouteil', 'lieu', 'vendr', 'barriqu', 'mang', 'bel', 'volaill', 'cour', 'graiss', 'souli', 'chass', 'lard', 'cochon', 'tard', 'point', 'apercevoir', 'val', 'mieux', 'plant', 'spécul'], tags=None),\n",
              " TaggedDocument(words=['aim', 'fromag'], tags=None),\n",
              " TaggedDocument(words=['édit', 'incun', 'météorolog', 'version', 'manuscrit', 'imprim', 'text', 'transm', 'commentair', 'accompagn', 'discuss', 'autour', 'alchim'], tags=None),\n",
              " TaggedDocument(words=['achet', 'vêt', 'beau', 'pull', 'chaud', 'bel', 'rob'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'occup'], tags=None),\n",
              " TaggedDocument(words=['avez', 'sûr', 'été', 'bel', 'femm', 'désir', 'courtis', 'époqu'], tags=None),\n",
              " TaggedDocument(words=['surviv'], tags=None),\n",
              " TaggedDocument(words=['entendu', 'opin', 'voudr', 'annonc'], tags=None),\n",
              " TaggedDocument(words=['peur', 'huis', 'clos', 'retrait'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'avantag', 'paris'], tags=None),\n",
              " TaggedDocument(words=['tâch', 'pourr', 'accompl'], tags=None),\n",
              " TaggedDocument(words=['sportiv', 'ador', 'natur', 'horreur', 'aller', 'discothequ'], tags=None),\n",
              " TaggedDocument(words=['immens', 'major', 'langu', 'condamn', 'disparaîtr', 'court', 'term'], tags=None),\n",
              " TaggedDocument(words=['mieux', 'vaut', 'exprim', 'paradox', 'méconnaîtr'], tags=None),\n",
              " TaggedDocument(words=['barrault', 'port', 'barbich', 'pinc', 'nez', 'vint', 'boir', 'vin', 'muscat', 'vill', 'déclar', 'flatt', 'confianc', 'témoign', 'membr', 'enseign', 'secondair'], tags=None),\n",
              " TaggedDocument(words=['vois', 'per', 'week', 'end'], tags=None),\n",
              " TaggedDocument(words=['mémoir', 'lexical', 'enregistr', 'carrosser', 'mot', 'mémoir', 'sémant', 'compil', 'sen'], tags=None),\n",
              " TaggedDocument(words=['forc', 'fair', 'attent', 'allez', 'fin', 'fair', 'mal'], tags=None),\n",
              " TaggedDocument(words=['homm', 'lorsqu', 'port', 'regard', 'réflex', 'jug', 'spontan', 'libr', 'mesur', 'agir', 'simpl', 'fonction', 'volont'], tags=None),\n",
              " TaggedDocument(words=['copain', 'heureux', 'vivr', 'franc'], tags=None),\n",
              " TaggedDocument(words=['meilleur', 'ami'], tags=None),\n",
              " TaggedDocument(words=['exempl', 'moyen', 'techniqu', 'haplodiploïdis', 'fix', 'rapid', 'caracter', 'génotyp', 'sélect', 'classiqu'], tags=None),\n",
              " TaggedDocument(words=['clameur', 'strident', 'mont', 'ensuit', 'entend', 'sort', 'halet'], tags=None),\n",
              " TaggedDocument(words=['général', 'question', 'robot', 'suscit', 'fois', 'engou', 'craint', 'grand', 'public'], tags=None),\n",
              " TaggedDocument(words=['jam'], tags=None),\n",
              " TaggedDocument(words=['serveur', 'mal', 'organis', 'dommag'], tags=None),\n",
              " TaggedDocument(words=['lorsqu', 'été', 'construit', 'tour', 'eiffel', 'monu', 'élev', 'mond', 'rest', 'an'], tags=None),\n",
              " TaggedDocument(words=['cuiller', 'exist'], tags=None),\n",
              " TaggedDocument(words=['robust', 'particuli', 'appréci', 'chass', 'caribou', 'déplac', 'traîneau'], tags=None),\n",
              " TaggedDocument(words=['oui', 'voyag', 'second'], tags=None),\n",
              " TaggedDocument(words=['oui', 'bon'], tags=None),\n",
              " TaggedDocument(words=['don', 'manipul', 'acquis', 'lectur', 'mémoir', 'proven', 'péripher', 'intern', 'extern'], tags=None),\n",
              " TaggedDocument(words=['tient', 'promess', 'tourment', 'femm', 'magicien'], tags=None),\n",
              " TaggedDocument(words=['opposit', 'sent', 'plac', 'occup', 'mond', 'rendu', 'humeur', 'fort', 'inégal'], tags=None),\n",
              " TaggedDocument(words=['météo', 'sujet', 'prédilect', 'réseau', 'social'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'promen'], tags=None),\n",
              " TaggedDocument(words=[], tags=None),\n",
              " TaggedDocument(words=['élev', 'fomo', 'associ', 'humeur', 'fréquent', 'négat', 'faibl', 'satisfact', 'vi', 'général', 'symptôm', 'dépress'], tags=None),\n",
              " TaggedDocument(words=['ascagn', 'jur', 'veng', 'fabric'], tags=None),\n",
              " TaggedDocument(words=['entré', 'mod', 'veil', 'agenc', 'spatial', 'européen', 'esa', 'reçoit', 'don', 'perdu', 'contact', 'samed', '00h36', 'gmt', '01h36', 'heur', 'paris', 'déclar', 'philipp', 'gaudon', 'chef', 'projet', 'roset', 'cne', 'centr', 'national', 'étud', 'spatial', 'toulous', 'sud', 'franc'], tags=None),\n",
              " TaggedDocument(words=['term', 'géohistoir', 'défin', 'fernand', 'braudel', 'lorsqu', 'chois', 'méditerran', 'objet', 'thes', '1949', 'été', 'repr', 'anné', '1980', 'géograph', 'utilis', 'outil', 'récent', 'pens', 'territoir', 'réexamin', 'non', 'espac', 'histor', 'révolus', 'simultan', 'consider', 'région', 'temp', 'périod', 'objet', 'formalis'], tags=None),\n",
              " TaggedDocument(words=['autour', 'coul', 'grand', 'ruissel', 'seau', 'eau', 'chaud', 'promen', 'vid', 'trait', 'robinet', 'eau', 'froid', 'piss', 'haut', 'éclabouss', 'battoir', 'égouttur', 'ling', 'rinc', 'mar', 'pataug', 'allant', 'petit', 'ruisseau', 'dall', 'pent', 'milieu', 'cris', 'coup', 'cadenc', 'bruit', 'murmur', 'plui', 'clameur', 'orag', 'étouff', 'plafond', 'mouill', 'machin', 'vapeur', 'droit', 'blanch', 'ros', 'fin', 'halet', 'ronfl', 'relâch', 'trépid', 'dans', 'vol', 'sembl', 'regl', 'énorm', 'tapag'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'appareil', 'commencent', 'pein', 'arriv', 'fin', 'vi', 'beaucoup', 'entrepris', 'moment', 'prépar', 'réel', 'trait'], tags=None),\n",
              " TaggedDocument(words=['créatric', 'emplois', 'fili', 'rééquilibr', 'balanc', 'commercial', 'désavantag', 'diversifi', 'activ', 'local'], tags=None),\n",
              " TaggedDocument(words=['sugger', 'kassák', 'dévoil', 'combin', 'appris', 'vivr', 'recour', 'mensong'], tags=None),\n",
              " TaggedDocument(words=['grand', 'famill', 'usag', 'nom', 'apparten', 'patronym'], tags=None),\n",
              " TaggedDocument(words=['américain', 'bien', 'chanc'], tags=None),\n",
              " TaggedDocument(words=['tart', 'cuit', 'sort', 'four', 'retourn', 'serv'], tags=None),\n",
              " TaggedDocument(words=['bon', 'not', 'franc', 'aujourd'], tags=None),\n",
              " TaggedDocument(words=['bien', 'consomm', 'model', 'limit', 'achat', 'produit', 'fabriqu', 'hexagon', 'entrepris', 'français', 'vit', 'rattrap', 'dur', 'réalit'], tags=None),\n",
              " TaggedDocument(words=['espéron', 'réduir', 'del', 'command', 'exig', 'trait', 'grand', 'réactiv'], tags=None),\n",
              " TaggedDocument(words=['met', 'boug', 'pot'], tags=None),\n",
              " TaggedDocument(words=['accident'], tags=None),\n",
              " TaggedDocument(words=['faut', 'savoir', 'éduc', 'complet', 'chien', 'guid', 'coût', 'cher', 'franc', 'écol', 'entier', 'financ', 'don'], tags=None),\n",
              " TaggedDocument(words=['argent', 'falloir'], tags=None),\n",
              " TaggedDocument(words=['épidem', 'rag', 'menac', 'sagunt', 'possed', 'pain', 'saint', 'hubert', 'patron', 'chasseur', 'guérisseur', 'enrag'], tags=None),\n",
              " TaggedDocument(words=['faut', 'utilis', 'mot', 'famili', 'entretien'], tags=None),\n",
              " TaggedDocument(words=['sort', 'monstr', 'têt'], tags=None),\n",
              " TaggedDocument(words=['cour', 'méchan', 'informat'], tags=None),\n",
              " TaggedDocument(words=['veux', 'vrai', 'trist'], tags=None),\n",
              " TaggedDocument(words=['grand', 'vill', 'proposent', 'moyen', 'transport', 'derni', 'inconvénient'], tags=None),\n",
              " TaggedDocument(words=['crépuscul', 'attend', 'pati', 'oubli', 'rend'], tags=None),\n",
              " TaggedDocument(words=['habit', 'new', 'york'], tags=None),\n",
              " TaggedDocument(words=['ête', 'mari'], tags=None),\n",
              " TaggedDocument(words=['question', 'surv', 'expliquent', 'réduir', 'impact', 'écolog', 'prélev', 'ressourc', 'naturel', 'volont', 'promouvoir', 'valeur', 'altruism', 'cooper', 'lois'], tags=None),\n",
              " TaggedDocument(words=['imagin', 'irrit', 'obstacl', 'empar', 'existent'], tags=None),\n",
              " TaggedDocument(words=['55', 'an', 'mort'], tags=None),\n",
              " TaggedDocument(words=['appel', 'thom', 'an'], tags=None),\n",
              " TaggedDocument(words=['caracter', 'commod', 'nou', 'amiti', 'sincer'], tags=None),\n",
              " TaggedDocument(words=['animal', 'maison', 'souhait', 'manqu', 'rien', 'nourritur'], tags=None),\n",
              " TaggedDocument(words=['europ', 'bien', 'europ', 'français', 'clair', 'nouvian', 'été', 'récompens', 'combat', 'sein', 'associ', 'bloom', 'cré', '2005', 'préserv', 'biodivers', 'océan'], tags=None),\n",
              " TaggedDocument(words=['milieu', 'chasseur', 'débrouill', 'pist', 'suiv', 'long', 'jour', 'bêt', 'égar', 'bless'], tags=None),\n",
              " TaggedDocument(words=['aut', 'an'], tags=None),\n",
              " TaggedDocument(words=['avion', 'besoin', 'aid'], tags=None),\n",
              " TaggedDocument(words=['géner', 'consomm', 'beaucoup', 'imag', 'réseau', 'social', 'petit', 'frustrat'], tags=None),\n",
              " TaggedDocument(words=['ici', 'mari'], tags=None),\n",
              " TaggedDocument(words=['universel', 'inlass', 'plui', 'dis', 'malheur'], tags=None),\n",
              " TaggedDocument(words=['écran', 'moniteur', 'fig', 'command', 'répondent'], tags=None),\n",
              " TaggedDocument(words=['espac', 'parcouru', 'campagn', 'petit', 'bourgad', 'possed', 'final', 'cohérent', 'propr', 'aver', 'beaucoup', 'marqu', 'arriv', 'paris'], tags=None),\n",
              " TaggedDocument(words=['aim', 'don', 'billet', 'euros'], tags=None),\n",
              " TaggedDocument(words=['per', 'jardin', 'arros', 'fleur'], tags=None),\n",
              " TaggedDocument(words=['oubli', 'nettoi', 'maison'], tags=None),\n",
              " TaggedDocument(words=['téléphon', 'son', 'répondu', 'immédiat'], tags=None),\n",
              " TaggedDocument(words=['bien', 'franc'], tags=None),\n",
              " TaggedDocument(words=['sub', 'époux', 'ardeur', 'répugn'], tags=None),\n",
              " TaggedDocument(words=['possibil', 'vers', 'indemn', 'kilometr', 'utilisent', 'véhicul', 'personnel', 'travail'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'part', 'expos'], tags=None),\n",
              " TaggedDocument(words=['cascad', 'sottis', 'don', 'beau', 'jeu', 'rieur', 'recommand', 'bon', 'humeur', 'nuit', 'blanch', 'forc', 'rir'], tags=None),\n",
              " TaggedDocument(words=['coinc', 'téléphon', 'oreil', 'épaul', 'attrap', 'jean'], tags=None),\n",
              " TaggedDocument(words=['raison', 'sécheress', 'réduit', 'récolt', 'gouverneur', 'bradford', 'proclam', 'journ', 'jeûn', 'prier'], tags=None),\n",
              " TaggedDocument(words=['amuseur', 'stipendi', 'exig', 'soir', 'jou', 'farc', 'intellectuel', 'nez', 'imbécil'], tags=None),\n",
              " TaggedDocument(words=['cass'], tags=None),\n",
              " TaggedDocument(words=['heureux', 'spectateur', 'aient', 'applaud'], tags=None),\n",
              " TaggedDocument(words=['descendus', 'zomb', 'troquet', 'coin', 'bu', 'caf', 'affil', 'enfourch', 'moto', 'venus', 'rendorm', 'aupres', 'affreux', 'fauteuil', 'skaï', 'noir'], tags=None),\n",
              " TaggedDocument(words=['dû', 'reprendr', 'problem', 'sant', 'beaucoup', 'bien', 'moral'], tags=None),\n",
              " TaggedDocument(words=['oubl', 'appareil', 'photo'], tags=None),\n",
              " TaggedDocument(words=['bigquery', 'entrepôt', 'don', 'entrepris', 'googl', 'mod', 'serveur'], tags=None),\n",
              " TaggedDocument(words=['famill', 'chant'], tags=None),\n",
              " TaggedDocument(words=['franc'], tags=None),\n",
              " TaggedDocument(words=['matin', 'prend', 'pet', 'déjeun', '8', 'heur'], tags=None),\n",
              " TaggedDocument(words=['dans', 'tub', 'club', 'doroth', 'princ', 'bel', 'air'], tags=None),\n",
              " TaggedDocument(words=['demand', 'aid', 'alouet'], tags=None),\n",
              " TaggedDocument(words=['homm', 'point', 'été', 'baptis', 'bon', 'anabapt', 'nomm', 'jacqu', 'vit', 'mani', 'cruel', 'ignomini', 'trait', 'frer', 'pied', 'plum', 'âme'], tags=None),\n",
              " TaggedDocument(words=['nuit', 'tomb', 'fais', 'vent', 'froid'], tags=None),\n",
              " TaggedDocument(words=['présent', 'rat', 'téléspect', 'chaîn', 'présent'], tags=None),\n",
              " TaggedDocument(words=['second', 'part', 'trait', 'rôl', 'encombr', 'stériqu', 'régiosélect', 'oxyd', 'métabol'], tags=None),\n",
              " TaggedDocument(words=['aim', 'cont', 'histoir', 'fantast', 'temp', 'temp', 'dis', 'sort', 'droit', 'histoir'], tags=None),\n",
              " TaggedDocument(words=['nouvel', 'technolog'], tags=None),\n",
              " TaggedDocument(words=['but', 'fabriqu', 'géner', 'ingénieur', 'informaticien', 'expliqu', 'david', 'wilgenbus'], tags=None),\n",
              " TaggedDocument(words=['sugger', 'propos', 'recommand'], tags=None),\n",
              " TaggedDocument(words=['achet', 'billet', 'train'], tags=None),\n",
              " TaggedDocument(words=['prélev', 'laboratoir', 'effectu', 'test', 'détermin', 'group', 'sanguin', 'facteur', 'rhésus'], tags=None),\n",
              " TaggedDocument(words=['fac', 'plat', 'nez', 'camard', 'luis', 'eût', 'frott', 'huil', 'dos', 'rond', 'encolur', 'épaiss', 'dandin', 'machinal', 'pens', 'bêt', 'our', 'difform', 'monstrueux'], tags=None),\n",
              " TaggedDocument(words=['attitud', 'xénophob', 'consider', 'violat', 'droit', 'homm'], tags=None),\n",
              " TaggedDocument(words=['redon', 'confianc'], tags=None),\n",
              " TaggedDocument(words=['aim', 'livr', 'poes'], tags=None),\n",
              " TaggedDocument(words=['effet', 'dévast', 'insect', 'pollinis', 'prouv', 'néonicotinoïd', 'néfast', 'mammifer', 'humain'], tags=None),\n",
              " TaggedDocument(words=['insist', 'caus', 'négat', 'allong', 'erranc', 'pet', 'job', 'emploi', 'précair', 'difficult', 'stress', 'étud'], tags=None),\n",
              " TaggedDocument(words=['bison', 'été', 'animal', 'sacr', 'indien', 'plain', 'crucial', 'cultur'], tags=None),\n",
              " TaggedDocument(words=['demand', 'calm', 'puiss', 'profit', 'rep', 'calm'], tags=None),\n",
              " TaggedDocument(words=['appel', 'angélic', 'summ', '12', 'an', 'canadien'], tags=None),\n",
              " TaggedDocument(words=['rével', 'secret'], tags=None),\n",
              " TaggedDocument(words=['arrêt', 'brass', 'écout', 'cloch', 'halt', 'sembl', 'éloign'], tags=None),\n",
              " TaggedDocument(words=['jou', 'ordin'], tags=None),\n",
              " TaggedDocument(words=['construct', 'motocyclet', 'particuli', 'châss', 'conçus', 'fonction', 'utilis', 'machin', 'contraint', 'support'], tags=None),\n",
              " TaggedDocument(words=['construct', 'rout', 'infrastructur', 'forêt', 'entraîn', 'afflux', 'popul', 'incontrôl', 'accroîtr', 'débois'], tags=None),\n",
              " TaggedDocument(words=['moder', 'charg', 'détermin', 'contenus', 'enfreignent', 'regl', 'plateform', 'esper', 'mettr', 'point', 'system', 'fois', 'humain', 'automatis', 'détect', 'messag', 'problémat'], tags=None),\n",
              " TaggedDocument(words=['vient', 'tour', 'soeur', 'aîn', 'plong', '39e', 'épisod', 'éniem', 'ser', 'américain', 'smartphon'], tags=None),\n",
              " TaggedDocument(words=['saut', 'canap'], tags=None),\n",
              " TaggedDocument(words=['vois', 'sign', 'épidem', 'répond', 'marqu'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'difficil'], tags=None),\n",
              " TaggedDocument(words=['fantast', 'allong', 'esper', 'vi', '76', '7', 'an', 'homm', '83', '8', 'femm', 'déroul', 'bel', 'décen'], tags=None),\n",
              " TaggedDocument(words=['sollicit', 'incess', 'somm', 'confront', 'obligent', 'disciplin', 'fer'], tags=None),\n",
              " TaggedDocument(words=['devon', 'prépar', 'nouvel', 'mutat', 'coronavirus', 'dépendr', 'uniqu', 'ue', 'product', 'vaccin', 'géner', 'ajout'], tags=None),\n",
              " TaggedDocument(words=['princ', 'vêtu'], tags=None),\n",
              " TaggedDocument(words=['tourist', 'national', 'impatientent', 'milieu', 'revendeur', 'sauvet'], tags=None),\n",
              " TaggedDocument(words=['lir', 'écrir', 'compt', 'apprentissag', 'indispens'], tags=None),\n",
              " TaggedDocument(words=['appel', 'camill', 'enfant', 'rêv', 'plein', 'têt'], tags=None),\n",
              " TaggedDocument(words=['reprendr', 'forc', 'long', 'jour', 'march'], tags=None),\n",
              " TaggedDocument(words=['étud', 'port', '133', 'pay', 'développ', 'indiqu', 'migrat', 'vill', 'entraîn', 'doubl', 'consomm', 'plat', 'gras', 'sucr', 'cher', 'immédiat', 'disponibl', 'detr', 'nourritur', 'traditionnel', 'coûteux', 'nécessit', 'temp', 'long', 'prépar'], tags=None),\n",
              " TaggedDocument(words=['part', 'travaill', 'équip', 'commercial', 'respons', 'vent'], tags=None),\n",
              " TaggedDocument(words=['peupl', 'côt', 'alask', 'été', 'particuli', 'touch', 'polit'], tags=None),\n",
              " TaggedDocument(words=['éligibl', 'forêt', 'arbre', 'metr', 'feuillag', 'recouvr', 'surfac'], tags=None),\n",
              " TaggedDocument(words=['mani', 'original', 'abord', 'question', 'réchauff', 'planétair', 'incit', 'dialogu'], tags=None),\n",
              " TaggedDocument(words=['boulot', 'long', 'difficil'], tags=None),\n",
              " TaggedDocument(words=['mang'], tags=None),\n",
              " TaggedDocument(words=['chang', 'personnel', 'valoris', 'trentain', 'anné', 'devenu', 'incant', 'collect'], tags=None),\n",
              " TaggedDocument(words=['final', 'désert', 'boisson', 'chaud', 'rével', 'rafraîch'], tags=None),\n",
              " TaggedDocument(words=['hi', 'soir', 'heur', 'dem', 'arriv', 'marronni', 'feuill', 'jol', 'petit', 'feuill', 'grand'], tags=None),\n",
              " TaggedDocument(words=['sourc', 'veulent', 'fair', 'potag', 'veulent', 'part', 'propr', 'légum', 'veulent', 'chois', 'phénomen', 'vrai', 'dur', 'prolong', 'prochain', 'anné'], tags=None),\n",
              " TaggedDocument(words=['voyon', 'vient', 'maison', 'faison', 'devoir', 'ensembl'], tags=None),\n",
              " TaggedDocument(words=['devenu', 'fil', 'temp', 'fêt', 'chrétien'], tags=None),\n",
              " TaggedDocument(words=['vend', 'livr'], tags=None),\n",
              " TaggedDocument(words=['invit', 'voul', 'boir', 'champagn'], tags=None),\n",
              " TaggedDocument(words=['progress', 'démograph', 'développ', 'class', 'moyen', 'mond', 'system', 'éduc', 'devoir', 'form', 'ici', '2050', 'aut', 'étudi', 'histoir', 'human', 'réun', 'ici', 'infospher', 'continu', 'expans', 'vertigin', 'mass', 'connaiss', 'doubl', 'an'], tags=None),\n",
              " TaggedDocument(words=['écri', 'marquis'], tags=None),\n",
              " TaggedDocument(words=['anné', 'hiv', 'rud'], tags=None),\n",
              " TaggedDocument(words=['fort', 'succes', 'rog', 'rougi', 'continu', 'développ', 'approch', 'amus', 'apprentissag'], tags=None),\n",
              " TaggedDocument(words=['dénou', 'ruban', 'attach', 'manch', 'quenouill', 'corsag', 'tend', 'quenouill'], tags=None),\n",
              " TaggedDocument(words=['plupart', 'cas', 'désignent', 'cour', 'enseign', 'espac', 'vi', 'ponctu', 'conquêt', 'progress', 'libert', 'nich', 'interstic', 'organis', 'scolair', 'temp', 'amour', 'amiti', 'premi', 'fois', 'rond', 'min', 'band', 'cod', 'cach', 'fous', 'rir'], tags=None),\n",
              " TaggedDocument(words=['coup', 'regard', 'tomb', 'fouill', 'madri', 'étui', 'bois', 'triangulair', 'roug'], tags=None),\n",
              " TaggedDocument(words=['rosal', 'littl', 'thund', 'amérindien', 'sioux', 'lakot', 'pri', 'hiv', 'trop', 'rigour', 'wyoming'], tags=None),\n",
              " TaggedDocument(words=['lutt', 'li', 'déconstruisent', 'rapport', 'domin', 'exploit', 'conquêt', 'nom', 'homm', 'lettr', 'capital', 'dissimul', 'postur', 'prédatric', 'incarn'], tags=None),\n",
              " TaggedDocument(words=['discour', 'jeuness', 'sérieux', 'mettent', 'scen', 'aspect', 'dramat', 'expérient', 'écras', 'angoiss', 'contradict', 'societ'], tags=None),\n",
              " TaggedDocument(words=['per', 'mort', 'ici'], tags=None),\n",
              " TaggedDocument(words=['quarti', 'beau', 'magasin', 'produit', 'grand', 'marqu'], tags=None),\n",
              " TaggedDocument(words=['confirm', 'organis', 'représent', '155', '000', 'inuit', 'canad', 'alask', 'groenland', 'russ', 'envisag', 'dépos', 'recour', 'jurid', 'commiss', 'interaméricain', 'droit', 'homm'], tags=None),\n",
              " TaggedDocument(words=['davantag', 'enclin', 'adher', 'thes'], tags=None),\n",
              " TaggedDocument(words=['cass', 'jamb', 'beaucoup', 'souffert'], tags=None),\n",
              " TaggedDocument(words=['médecin'], tags=None),\n",
              " TaggedDocument(words=['né', 'pay'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'stag', 'plaît', 'beaucoup'], tags=None),\n",
              " TaggedDocument(words=['appel', 'hugo', 'an'], tags=None),\n",
              " TaggedDocument(words=['présent', 'professionnel', 'grâc', 'propr', 'accultur', 'norm', 'valeur', 'idéolog', 'véhicul', 'format', 'milieu', 'professionnel', 'identifi', 'model', 'transm', 'histoir'], tags=None),\n",
              " TaggedDocument(words=['bon', 'idé'], tags=None),\n",
              " TaggedDocument(words=['non', 'bien', 'sûr', 'veux', 'préoccup', 'chang'], tags=None),\n",
              " TaggedDocument(words=['cas', 'égal', 'vic', 'président', 'kamal', 'harr', 'dispos', 'voix', 'départag', 'vot'], tags=None),\n",
              " TaggedDocument(words=['aut', 'vrai', 'effort', 'crédibl'], tags=None),\n",
              " TaggedDocument(words=['habitud', 'jam', 'peur'], tags=None),\n",
              " TaggedDocument(words=['fi'], tags=None),\n",
              " TaggedDocument(words=['descend', 'escali', 'vitess', 'courut', 'rencontr'], tags=None),\n",
              " TaggedDocument(words=['milli', 'mortifer', 'tournent', 'rond', 'caleb', 'île', 'archipel', 'arqué', 'des', 'inquiet', 'ni', 'dir', 'anxiet', 'maternel', 'proteg', 'ténuit', 'délicat', 'sépar', 'amer', 'flanc', 'sécrètent', 'europ', 'bon', 'liqueur', 'gulf', 'stream', 'vers', 'incandescent', 'equateur', 'funambul', 'afriqu', 'île', 'non', 'clôtur', 'clair', 'audac', 'arrier', 'polynes', 'guadeloup', 'fendu', 'rai', 'dorsal', 'miser', 'haït', 'négritud', 'mit', 'fois', 'croi', 'human', 'comiqu', 'petit', 'queu', 'florid', 'negr', 'achev', 'strangul', 'afriqu', 'gigantesqu', 'chenill', 'pied', 'hispan', 'europ', 'nudit', 'mort', 'fauch', 'larg', 'andain'], tags=None),\n",
              " TaggedDocument(words=['franc', 'situ', '25em', 'rang', 'class', 'toefl', 'test', 'international', 'anglais'], tags=None),\n",
              " TaggedDocument(words=['societ', 'modern', 'demandent', 'beaucoup', 'jeun', 'exigent', 'soient', 'libr', 'sérieux', 'autonom', 'prévoi', 'original', 'conform'], tags=None),\n",
              " TaggedDocument(words=['ros', 'beaucoup', 'chang', 'ici', '40', 'an'], tags=None),\n",
              " TaggedDocument(words=['écol', 'adapt', 'xxi', 'siecl', 'progress', 'démograph', 'développ', 'class', 'moyen', 'mond', 'system', 'éduc', 'devoir', 'form', 'ici', '2050', 'aut', 'étudi', 'histoir', 'human', 'réun'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'présent', 'famill'], tags=None),\n",
              " TaggedDocument(words=['apprentissag', 'cod', 'larg', 'cultur', 'général', 'numer', 'écol', 'mesur', 'réclam', 'academ', 'scienc'], tags=None),\n",
              " TaggedDocument(words=['achet', 'franc', 'préserv', 'emploi', 'franc', 'évit', 'éventuel', 'fermetur', 'usin', 'synonym', 'chômag', 'paupéris'], tags=None),\n",
              " TaggedDocument(words=['reconnaîtr'], tags=None),\n",
              " TaggedDocument(words=['propos', 'pans', 'djokovic', 'port', 'impos', 'côt', 'droit', 'sangl', 'abdominal'], tags=None),\n",
              " TaggedDocument(words=['ouvr', 'port', 'chien', 'court', 'extérieur'], tags=None),\n",
              " TaggedDocument(words=['véhicul', 'autonom', 'besoin', 'chauffeur', 'oper', 'chirurgical', 'robotis', 'min', 'exploit', 'robot'], tags=None),\n",
              " TaggedDocument(words=['polit', 'vaccinal', 'accompagn', 'dout', 'effet', 'secondair', 'estim', 'import', 'chercheur'], tags=None),\n",
              " TaggedDocument(words=['soir', 'rentr', 'vrai', 'fatigu', 'heureux'], tags=None),\n",
              " TaggedDocument(words=['carott', 'cru', 'croient', 'croqu', 'cré', 'cramp'], tags=None),\n",
              " TaggedDocument(words=['plui', 'cess', 'tomb', 'serion', 'amus'], tags=None),\n",
              " TaggedDocument(words=['caus', 'cris', 'entrepris', 'licenci', 'centain', 'salari'], tags=None),\n",
              " TaggedDocument(words=['vendus', 'form', 'petit', 'format', 'noir', 'blanc', 'jeux', 'entraîn', 'raison', 'jeux', 'calcul', 'mental', 'trompent', 'bien', 'pet', 'mond'], tags=None),\n",
              " TaggedDocument(words=['expérient', 'été', 'fait', 'démontrent', 'enfant', 'aptitud', 'mimet', 'phoniqu', 'capac', 'acquer', 'non', 'vocabulair', 'syntax', 'prononci'], tags=None),\n",
              " TaggedDocument(words=['fêt', 'arriv', '19e', 'siecl', 'état', 'unis', 'canad', 'grâc', 'émigr', 'venus', 'irland', 'écoss'], tags=None),\n",
              " TaggedDocument(words=['bu', 'tass', 'thé', 'caf', 'rentr', 'bus'], tags=None),\n",
              " TaggedDocument(words=['luc', 'postul', 'travaill', 'monitric', 'camp', 'vacanc', 'international', 'été'], tags=None),\n",
              " TaggedDocument(words=['histoir', 'pass', 'asi'], tags=None),\n",
              " TaggedDocument(words=['époqu', 'actuel', 'des', 'résid', 'consomm', 'objet', 'sophistiqu', 'reflètent', 'nouveaut'], tags=None),\n",
              " TaggedDocument(words=['devenu', 'rituel', 'vigueur', 'famill', 'franc', 'phénomen', 'portabl', 'remport', 'aupres', 'adolescent', 'succes', 'pay', 'scandinav'], tags=None),\n",
              " TaggedDocument(words=['excus', '30', 'minut', 'attend', 'tabl'], tags=None),\n",
              " TaggedDocument(words=['revient', 'europ', 'vagu', 'chaleur', 'touch', 'continent', 'épargn', 'aucun', 'part', 'part', 'mond', 'situ', 'nord', 'scandinav', 'thermometr', 'grimp', 'flech'], tags=None),\n",
              " TaggedDocument(words=['jogging', 'matinal', 'devenu', 'cours', 'obstacl', 'évit', 'pass'], tags=None),\n",
              " TaggedDocument(words=['deven', 'ami', 'fill', 'sup', 'difficil'], tags=None),\n",
              " TaggedDocument(words=['truism', 'économ', 'fonction', 'bien', 'haut', 'rationalis', 'unifi', 'exig', 'étalon', 'échang', 'stabl'], tags=None),\n",
              " TaggedDocument(words=['voitur', 'aim', 'beaucoup', 'prendr', 'métro'], tags=None),\n",
              " TaggedDocument(words=['bateau', 'serr', 'contr', 'été', 'équip', 'défens', 'voisin', 'rest', 'intact'], tags=None),\n",
              " TaggedDocument(words=['dégoût', 'élev'], tags=None),\n",
              " TaggedDocument(words=['pens', 'espion', 'marqu', 'per', 'fall', 'ménag', 'despot', 'séver', 'furieux', 'démiss', 'forc'], tags=None),\n",
              " TaggedDocument(words=['interdict', 'cigaret', 'électron', 'désastr', 'entrepris'], tags=None),\n",
              " TaggedDocument(words=['propos', 'jou', 'film', 'répondu', 'oui', 'suit', 'occas', 'vi'], tags=None),\n",
              " TaggedDocument(words=['répar', 'voitur'], tags=None),\n",
              " TaggedDocument(words=['ok', 'problem'], tags=None),\n",
              " TaggedDocument(words=['soeur', 'venu', 'hi', 'visit'], tags=None),\n",
              " TaggedDocument(words=['jam', 'ensuit', 'rejoint', 'quarti', 'modern', 'confluenc', 'fleuv', 'saôn', 'jet', 'rhôn'], tags=None),\n",
              " TaggedDocument(words=['trop', 'chaud', 'ouvr', 'fenêtr'], tags=None),\n",
              " TaggedDocument(words=['part', 'heur', 'part', 'neuf', 'heur', 'dem'], tags=None),\n",
              " TaggedDocument(words=['sénateur', 'élu', 'représent', 'proportionnel', 'sieg', 'devient', 'vac', 'caus', 'accept', 'fonction', 'gouvernemental', 'remplac', 'candidat', 'figur', 'list', 'immédiat', 'derni', 'candidat', 'devenu', 'sénateur', 'conform', 'ordre', 'list'], tags=None),\n",
              " TaggedDocument(words=['dommag', 'fil', 'poteau', 'balafrent', 'décor'], tags=None),\n",
              " TaggedDocument(words=['journé', 'longu', 'david', 'attend', 'samed', 'semain'], tags=None),\n",
              " TaggedDocument(words=['plupart', 'spectateur', 'appréci', 'piec', 'théâtr'], tags=None),\n",
              " TaggedDocument(words=['femm', 'revanch', 'surreprésent', 'dans', '62', 'pratiqu', 'davantag', 'gymnast', '79', 'not', 'inse'], tags=None),\n",
              " TaggedDocument(words=['export', 'cacao', 'doubl', 'rapport', 'anné', 'derni'], tags=None),\n",
              " TaggedDocument(words=['remis', 'sourir'], tags=None),\n",
              " TaggedDocument(words=['david', 'écol', 'mercred', 'matin'], tags=None),\n",
              " TaggedDocument(words=['attend', 'répons'], tags=None),\n",
              " TaggedDocument(words=['fois', 'lass', 'silenc', 'laiss', 'aller', 'plaisanter', 'esprit', 'mis', 'mouv', 'entraîn', 'audelà', 'mesur'], tags=None),\n",
              " TaggedDocument(words=['choix', 'mang', 'fromag', 'aop', 'mang', 'fromag', 'goût', 'terroir', 'particip', 'maintien', 'paysag', 'tradit', 'fromag', 'concern'], tags=None),\n",
              " TaggedDocument(words=['oui'], tags=None),\n",
              " TaggedDocument(words=['mond', 'regard', 'class', 'ensembl', 'écol', 'primair', 'évident', 'arriv', 'nouvel', 'éven'], tags=None),\n",
              " TaggedDocument(words=['parf', 'plat', 'jour', 'plaît'], tags=None),\n",
              " TaggedDocument(words=['vivr'], tags=None),\n",
              " TaggedDocument(words=['éti', 'arriv', 'heur', 'convenu', 'aur', 'début', 'reportag', 'auto', 'biograph', 'auteur', 'contemporain', 'convoit', 'moment'], tags=None),\n",
              " TaggedDocument(words=['roch', 'ferm'], tags=None),\n",
              " TaggedDocument(words=['ashton', 'lanc', 'not', 'grav', 'provoc', 'homicid', 'luc', 'pouss', 'plaint', 'aigu', 'arthur', 'modul', 'écart', 'son', 'moyen', 'bass', 'taill', 'ministr', 'ronfl', 'orgu', 'tand', 'voix', 'femm', 'répet', 'parol', 'repren', 'choeur', 'délici'], tags=None),\n",
              " TaggedDocument(words=['vrai', 'débat', 'societ', 'avantag', 'défenseur', 'jour', 'chôm'], tags=None),\n",
              " TaggedDocument(words=['imper', 'chien', 'laiss', 'promen'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'madagascar', '700', 'person', 'sortent', 'écol', 'informat'], tags=None),\n",
              " TaggedDocument(words=['coup', 'protest', 'contr', 'monsieur', 'bleu'], tags=None),\n",
              " TaggedDocument(words=['forêt', 'bien', 'aménag', 'pourr', 'ultérieur', 'fourn', 'nouvel', 'récolt', 'bois'], tags=None),\n",
              " TaggedDocument(words=['pass', 'farin', 'oeuf', 'battu', 'chapelur'], tags=None),\n",
              " TaggedDocument(words=['lûm', 'passag', 'émouv', 'rappel', 'jour', 'heureux', 'pass', 'pleur', 'fac', 'exist', 'miser', 'lendemain'], tags=None),\n",
              " TaggedDocument(words=['rebâchag', 'envoi', 'don', 'mémoir', 'tand', 'approch', 'sujet', 'permettr', 'dégag', 'sen', 'envoi', 'don', 'né', 'commun', 'coeur', 'mémoir', 'sémant', 'expliqu'], tags=None),\n",
              " TaggedDocument(words=['écol', 'trouv'], tags=None),\n",
              " TaggedDocument(words=['miam', 'dois', 'hât', 'revoir'], tags=None),\n",
              " TaggedDocument(words=['cuisin', 'pièc', 'préféré', 'maison'], tags=None),\n",
              " TaggedDocument(words=['intens', 'carbon', 'suiss', 'moder', 'grâc', 'faibl', 'intens', 'énerget', 'product', 'électr', 'presqu', 'total', 'décarbon'], tags=None),\n",
              " TaggedDocument(words=['crain', 'tabl', 'disponibl'], tags=None),\n",
              " TaggedDocument(words=['vrai', 'désol', 'oubli', 'achet', 'viand', 'rentr'], tags=None),\n",
              " TaggedDocument(words=['chapeau', 'envol', 'mont', 'voili'], tags=None),\n",
              " TaggedDocument(words=['auteur', 'exploit', 'terrain', 'erik', 'orsen', 'chevali', 'subjonct', 'sort', 'automn', '2004'], tags=None),\n",
              " TaggedDocument(words=['dans', 'nuit'], tags=None),\n",
              " TaggedDocument(words=['oui', 'attend', 'vacanc', 'été', 'impatient'], tags=None),\n",
              " TaggedDocument(words=['prom', 'polit', 'économ', 'men', 'europ', 'apport', 'prosper', 'plein', 'emploi'], tags=None),\n",
              " TaggedDocument(words=['travaillent', 'directeur', 'plaignent', 'beacoup'], tags=None),\n",
              " TaggedDocument(words=['don', 'serviet'], tags=None),\n",
              " TaggedDocument(words=['contraint', 'deviator', 'applique', 'temp', 'vari', '0', '240', 'minut', 'phas', 'consolid', 'contraint', 'confin'], tags=None),\n",
              " TaggedDocument(words=['chaud'], tags=None),\n",
              " TaggedDocument(words=['bédouin', 'blanc', 'peau', 'mat', 'tann', 'soleil'], tags=None),\n",
              " TaggedDocument(words=['légend', 'thanksgiving', 'veut', 'littéral', 'anglais', 'don', 'né', 'jour', 'aub', 'hiv', 'amer', 'colon', 'mayflow', '1621'], tags=None),\n",
              " TaggedDocument(words=['menu', 'mid', 'rest', 'rep'], tags=None),\n",
              " TaggedDocument(words=['choix', 'hôtel', 'dépend', 'bien', 'sûr', 'budget', 'envi'], tags=None),\n",
              " TaggedDocument(words=['vérit', 'biograph', 'langu', 'français', 'auteur', 'veulent', 'mettr', 'pendul', 'heur', 'malmen', 'queslqu', 'fauss', 'croyanc'], tags=None),\n",
              " TaggedDocument(words=['quitt', 'limog'], tags=None),\n",
              " TaggedDocument(words=['droit', 'artist', 'peint', 'arbre', 'touffu', 'fois', 'prometteur', 'inquiet'], tags=None),\n",
              " TaggedDocument(words=['gard', 'form', 'aid', 'temp', 'temp', 'maison', 'jardin'], tags=None),\n",
              " TaggedDocument(words=['démocrat', 'coler', 'voir', 'sénat', 'tu', 'priorit', 'prévoit', 'larry', 'sabato', 'politologu', 'univers', 'virgin'], tags=None),\n",
              " TaggedDocument(words=['mond', 'absorb', 'frivol', 'solennel', 'lir', 'coeur'], tags=None),\n",
              " TaggedDocument(words=['blog', 'rendu', 'fous'], tags=None),\n",
              " TaggedDocument(words=['âge'], tags=None),\n",
              " TaggedDocument(words=['lik', 'tweet', 'partag', 'messag', 'aut', 'sign', 'reconnaiss', 'social', 'deviennent', 'vérit', 'monnai', 'échang', 'affect'], tags=None),\n",
              " TaggedDocument(words=['formal', 'modif', 'nécessit', 'réalis', 'démarch', 'réalis', 'dossi', 'prépar', 'piec', 'justif', 'docu', 'joindr', 'dossi'], tags=None),\n",
              " TaggedDocument(words=['écol', 'aujourd', 'march', 'just', 'fair', 'repos', 'histoir', 'valeur', 'dit', 'pass'], tags=None),\n",
              " TaggedDocument(words=['gaio', 'histoir', 'plais'], tags=None),\n",
              " TaggedDocument(words=['junt', 'désign', 'remplac', 'nation', 'uni', 'tand', 'kyaw', 'mo', 'tun', 'assur', 'représent', 'pay', 'imbroglio', 'jurid', 'tranch', 'onu'], tags=None),\n",
              " TaggedDocument(words=['revanch', 'regret', 'engag', 'pris', 'ministr', 'débat', 'constitutionnel', 'mod', 'scrutin', 'été', 'respect'], tags=None),\n",
              " TaggedDocument(words=['simultan', 'foresti', 'convert', 'aménag', 'proced', 'exploit', 'sylvicol', 'rationnel'], tags=None),\n",
              " TaggedDocument(words=['fut', 'arriv', 'cimeti', 'agenouill', 'pri'], tags=None),\n",
              " TaggedDocument(words=['frer', 'patric', 'jeun'], tags=None),\n",
              " TaggedDocument(words=['travail', 'facteur', 'principal', 'homm', 'amélior', 'existent', 'perfectibil', 'développ'], tags=None),\n",
              " TaggedDocument(words=['math', 'peur', 'femm'], tags=None),\n",
              " TaggedDocument(words=['activ', 'héberg', 'tourist', 'conjugu', 'motiv'], tags=None),\n",
              " TaggedDocument(words=['valorisent', 'davantag', 'toler', 'ouvertur', 'métissag', 'culturel', 'solidar', 'indépend', 'esprit'], tags=None),\n",
              " TaggedDocument(words=['vrai', 'dû', 'beaucoup', 'insist', 'chois'], tags=None),\n",
              " TaggedDocument(words=['univers'], tags=None),\n",
              " TaggedDocument(words=['secour', 'verb', 'synonym', 'aid', 'dang', 'port', 'secour', 'quelqu'], tags=None),\n",
              " TaggedDocument(words=['voul', 'fair', 'musiqu', 'essai', 'pot', 'voi', 'pris', 'mis', 'sérieux'], tags=None),\n",
              " TaggedDocument(words=['bibliothequ', 'ferm', 'allé', 'hi', 'mid'], tags=None),\n",
              " TaggedDocument(words=['lucid', 'adolescent', 'mettent', 'point', 'conduit', 'cherch', 'reproduir', 'paraît', 'négat', 'comport', 'arriv', 'débord', 'émot', 'mobil', 'son', 'cour'], tags=None),\n",
              " TaggedDocument(words=['fois', 'pench', 'sourc', 'vit', 'décharn', 'hach', 'cicatric', 'levr', 'gerc', 'miser'], tags=None),\n",
              " TaggedDocument(words=['indiqu', 'femm', 'venu', 'semain', 'derni', 'beaucoup', 'bien', 'film'], tags=None),\n",
              " TaggedDocument(words=['vieux', 'rêv', 'encycloped', 'resurg', 'exposit', 'contemporain', 'nomm', 'clôtur', 'utop', 'planet', 'résum', 'panoram', 'ordre', 'mond', 'ramen', 'taill', 'parc', 'attract', 'regard', 'embrass', 'rest', 'recoin'], tags=None),\n",
              " TaggedDocument(words=['précipit', 'livr', 'mess', 'reli', 'velour', 'violet', 'mont', 'hât', 'laiss', 'échapp', 'imag', 'bord', 'bandeau', 'dentel', 'papi', 'jaun', 'marquent', 'pag', 'fêt', 'tant', 'aval', 'goutt', 'commenc', 'lir', 'vit', 'text', 'sacr', 'intelligent', 'léger', 'obscurc', 'incertitud', 'savoir', 'pris', 'eau', 'vichy', 'pepsin', 'capabl', 'rattrap', 'fair', 'descendr'], tags=None),\n",
              " TaggedDocument(words=['remont', 'bien', 'hiv', 'veil', 'jour', 'noël'], tags=None),\n",
              " TaggedDocument(words=['oubl', 'ven', 'chaussur', 'sport'], tags=None),\n",
              " TaggedDocument(words=['lund', 'mard', 'mercred'], tags=None),\n",
              " TaggedDocument(words=['prêt', 'stylos', 'plaît'], tags=None),\n",
              " TaggedDocument(words=['danois'], tags=None),\n",
              " TaggedDocument(words=['peur', 'part', 'adress'], tags=None),\n",
              " TaggedDocument(words=['enfant', 'racont', 'histoir', 'endorm'], tags=None),\n",
              " TaggedDocument(words=['quitt', 'étap', 'enfant', 'dessin', 'lieu', 'rencontr'], tags=None),\n",
              " TaggedDocument(words=['appel', 'docteur'], tags=None),\n",
              " TaggedDocument(words=['acte', 'gratuit', 'notion', 'philosoph', 'problémat', 'volont', 'prouv', 'libert', 'acte', 'suppos', 'mobil', 'constitu', 'mobil'], tags=None),\n",
              " TaggedDocument(words=['vrai', 'vi', 'social', 'satisfais', 'conduir', 'pass', 'temp', 'réseau', 'social'], tags=None),\n",
              " TaggedDocument(words=['regret', 'gest', 'furent', 'descendu', 'train'], tags=None),\n",
              " TaggedDocument(words=['soir', '25', 'août', '1830', 'théâtr', 'monnai', 'bruxel', 'don', 'représent', 'oper', 'muet', 'portic', 'sujet', 'trouv', 'soulev', 'napolitain', 'contr', 'oppresseur'], tags=None),\n",
              " TaggedDocument(words=['normal', 'enfant', 'ado', 'an', 'erre', 'plein', 'nuit', 'ru'], tags=None),\n",
              " TaggedDocument(words=['handicap', 'lorsqu', 'visibl', 'trop', 'associ', 'incompétent'], tags=None),\n",
              " TaggedDocument(words=['difficil'], tags=None),\n",
              " TaggedDocument(words=['bien', 'décid', 'vivr', 'fond', 'âge', 'adult'], tags=None),\n",
              " TaggedDocument(words=['fin', 'compt', 'révolu', 'conduit', 'remplac', 'monarch', 'absolu', 'monarch', 'constitutionnel', 'tour', 'remplac', 'républ'], tags=None),\n",
              " TaggedDocument(words=['fois', 'femm', 'enfant', 'marchent', 'milieu', 'group'], tags=None),\n",
              " TaggedDocument(words=['polic', 'ordon', 'pos', 'question', 'personnel'], tags=None),\n",
              " TaggedDocument(words=['moment', 'pai', 'pet', 'garçon', 'volontair'], tags=None),\n",
              " TaggedDocument(words=['ultim', 'sophist', 'auteur', 'réalis', 'ser', 'mettent', 'point', 'honneur', 'presqu', 'trouv', 'point', 'raccord', 'scen', 'an', 'séparent'], tags=None),\n",
              " TaggedDocument(words=['bien', 'content', 'aie', 'appréci', 'histoir'], tags=None),\n",
              " TaggedDocument(words=['respons', 'craignent', 'protocol', 'handicap', 'croissanc', 'économ', 'tand', 'mettent', 'profit', 'rapport', 'vent', 'perm', 'pollu'], tags=None),\n",
              " TaggedDocument(words=['canal', 'été', 'construit', 'vingt', 'an'], tags=None),\n",
              " TaggedDocument(words=['salut'], tags=None),\n",
              " TaggedDocument(words=['mech', 'cheveux', 'roux', 'crespel', 'natur', 'coll', 'brillantin', 'larg', 'trait', 'sculptur', 'grecqu', 'étudi', 'cess', 'peintr', 'mantou', 'création', 'figur', 'homm', 'tir', 'simpl', 'form', 'richess', 'vari', 'emprunt', 'natur', 'viv', 'chevelur', 'enroul', 'liss', 'bec', 'aigus', 'boucl', 'superposit', 'tripl', 'fleur', 'diadem', 'tress', 'air', 'fois', 'paquet', 'algu', 'nich', 'colomb', 'bandeau', 'jacinth', 'torsad', 'serpent'], tags=None),\n",
              " TaggedDocument(words=['vient', 'cérémon', 'soir'], tags=None),\n",
              " TaggedDocument(words=['berg', 'arriv', 'sort', 'grott'], tags=None),\n",
              " TaggedDocument(words=['plac'], tags=None),\n",
              " TaggedDocument(words=['bref', 'corp', 'enseign', 'fill', 'réuss', 'grâc', 'talent', 'bûcheux', 'tand', 'garçon', 'échouent', 'paress', 'manqu', 'don'], tags=None),\n",
              " TaggedDocument(words=['vivr', 'campagn', 'beaucoup', 'avantag'], tags=None),\n",
              " TaggedDocument(words=['mod', 'pens', 'mutil', 'conduit', 'action', 'mutil'], tags=None),\n",
              " TaggedDocument(words=['externalis', 'chaîn', 'product', 'diminu', 'coût', 'invest', 'product', 'frais', 'stockag', 'produit'], tags=None),\n",
              " TaggedDocument(words=['souhaiton', 'bon', 'voyag'], tags=None),\n",
              " TaggedDocument(words=['kant', 'ajout', 'précis', 'loi', 'moral', 'clair', 'conçu', 'raison', 'croirion', 'jam', 'autoris', 'admettr', 'chos', 'libert'], tags=None),\n",
              " TaggedDocument(words=['100', 'an', 'piec', 'monnai', 'val', 'argent'], tags=None),\n",
              " TaggedDocument(words=['pos', 'question', 'vi', 'peur', 'sottis', 'répond', 'pein'], tags=None),\n",
              " TaggedDocument(words=['ultracrépidarian', 'constitu', 'cas', 'exempl', 'utilis', 'argument', 'autor'], tags=None),\n",
              " TaggedDocument(words=['étud', 'concentr', 'impact', 'couvertur', 'malad', 'universel', 'taux', 'mortal', 'pay', 'développ'], tags=None),\n",
              " TaggedDocument(words=['général', 'moment', 'rend', 'compt', 'retard'], tags=None),\n",
              " TaggedDocument(words=['stigmatis', 'natur', 'échang', 'occas', 'cours', 'supermarch', 'exempl', 'question', 'marqu', 'yaourt'], tags=None),\n",
              " TaggedDocument(words=['reçois', 'exempl', 'coupl', 'franco', 'espagnol', 'envi', 'enfant', 'appren', 'anglais'], tags=None),\n",
              " TaggedDocument(words=['don', 'répons', 'demain'], tags=None),\n",
              " TaggedDocument(words=['pouv', 'aid'], tags=None),\n",
              " TaggedDocument(words=['oncle', 'tois', 'express', 'fureur', 'contenu', 'osait', 'crois', 'regard'], tags=None),\n",
              " TaggedDocument(words=['signif', 'courag', 'fair', 'chos'], tags=None),\n",
              " TaggedDocument(words=['garag', 'voitur', 'vélo'], tags=None),\n",
              " TaggedDocument(words=['idéal', 'choix'], tags=None),\n",
              " TaggedDocument(words=['protection', 'culturel', 'ensuit'], tags=None),\n",
              " TaggedDocument(words=['silhouet', 'élanc', 'grand', 'mannequin'], tags=None),\n",
              " TaggedDocument(words=['dîn', 'arthur', 'don', 'petit', 'friandis', 'ressort', 'assoup', 'tranquill', 'pani'], tags=None),\n",
              " TaggedDocument(words=['dress', 'lisi', 'champ', 'pâturag', 'haut', 'sombr', 'citadel', 'vast', 'barr', 'pan', 'horizon'], tags=None),\n",
              " TaggedDocument(words=['avi', 'cherch', 'acte', 'conven', 'aur', 'trouv', 'coup'], tags=None),\n",
              " TaggedDocument(words=['entrepris', 'développ', 'ailleur', 'projet', 'explor', 'spatial', 'lun', 'mar', 'programm', 'starlink', 'acces', 'haut', 'deb', 'internet', 'satellit', 'terr'], tags=None),\n",
              " TaggedDocument(words=['duroy', 'assit', 'canap', 'roug', 'tentur', 'mur', 'ressort', 'fatigu', 'enfonc', 'don', 'sensat', 'tomb', 'trou'], tags=None),\n",
              " TaggedDocument(words=['deven', 'uniform', 'monolingu', 'cerveau', 'affect', 'point', 'perdr', 'part', 'créativ', 'linguist', 'inné'], tags=None),\n",
              " TaggedDocument(words=['nécessair', 'fair', 'effort', 'pédagog', 'fair', 'adopt', 'nouvel', 'technolog', 'banalis'], tags=None),\n",
              " TaggedDocument(words=['éditeur', 'exploitent', 'créneau', 'internet', 'regorg', 'sit', 'intéress', 'permettent', 'approch', 'scolair', 'amus', 'mathémat'], tags=None),\n",
              " TaggedDocument(words=['aucun', 'idé'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'félin', 'bijoux', 'autour', 'cou', 'métal', 'perl', 'verr', 'coquillag'], tags=None),\n",
              " TaggedDocument(words=['divers', 'langu', 'été', 'perçu', 'entrav', 'échang', 'diffus', 'savoir'], tags=None),\n",
              " TaggedDocument(words=['aujourd', 'artist'], tags=None),\n",
              " TaggedDocument(words=['expliqu', 'différent', 'nécessair', 'utilis', 'concept', 'social', 'genr', 'doyal', '2003', 'comprendr', 'exempl', 'norm', 'social', 'favoris', 'adopt', 'tabag', 'homm', 'tardiv', 'femm'], tags=None),\n",
              " TaggedDocument(words=['étud', 'complet', 'chang', 'climat', 'régional'], tags=None),\n",
              " TaggedDocument(words=['travail', 'doctorat', 'port', 'développ', 'méthod', 'géner', 'extrair', 'éven', 'nouveau', 'pertinent', 'don', 'textuel', 'hétérogen'], tags=None),\n",
              " TaggedDocument(words=['97', 'colleg', 'utilis', 'portabl', 'interdit'], tags=None),\n",
              " TaggedDocument(words=['loin', 'gouvern', 'parvient', 'incarn', 'altern', 'droit', 'gaullism'], tags=None),\n",
              " TaggedDocument(words=['cuisin', 'piec', 'préfer', 'maison'], tags=None),\n",
              " TaggedDocument(words=['sondag', 'publi', 'mai', 'bva', 'syntec', 'numer', 'féder', 'professionnel', 'secteur', 'informat', 'favor', 'mesur', '87', 'franc', 'accord', 'programm', 'informat', 'soient', 'enseign', 'écol', '24', 'part', 'primair', '41', 'part', 'colleg'], tags=None),\n",
              " TaggedDocument(words=['engag', '16', 'an', 'résist', 'déput', 'sénateur', 'réuss', 'franc', 'conserv', '1968', 'fair', 'adopt', '1967', 'contr', 'major', 'camp', 'polit', 'loi', 'autoris', 'contracept'], tags=None),\n",
              " TaggedDocument(words=['jeun', 'aujourd', 'veut', 'écout', 'veut', 'écol', 'prépar', 'trouv', 'boulot', 'travail'], tags=None),\n",
              " TaggedDocument(words=['bonsoir', 'madam', 'aid'], tags=None),\n",
              " TaggedDocument(words=['fabric', 'montr', 'passeport', 'qualifi', 'marchand', 'barometr', 'port', 'marchandis'], tags=None),\n",
              " TaggedDocument(words=['100', 'squelet', 'complet', 'animal', 'été', 'découvert', 'ici', 'zon', 'petit', '100', 'm²', 'ouest', 'grand', 'templ'], tags=None),\n",
              " TaggedDocument(words=['blanc', 'noir'], tags=None),\n",
              " TaggedDocument(words=['aussitôt', 'eut', 'perdu', 'chien', 'cherch', 'désesper'], tags=None),\n",
              " TaggedDocument(words=['fêt', 'chrétien', 'célebr', 'naissanc', 'jésus'], tags=None),\n",
              " TaggedDocument(words=['final', 'réalis', 'berg', 'fois', 'repr', 'esprit'], tags=None),\n",
              " TaggedDocument(words=['disparit', 'langu', 'devr', 'préoccup', 'titr', 'espec', 'animal', 'végétal'], tags=None),\n",
              " TaggedDocument(words=['post', 'élev', 'particip', 'entrain', 'convers', 'fidel', 'égai', 'fumister', 'accident', 'arriv', 'mâchoir', 'renonc', 'prendr', 'pein', 'pouff', 'effect', 'livr', 'plac', 'mimiqu', 'conventionnel', 'signifi', 'fatigu', 'risqu', 'ri', 'larm'], tags=None),\n",
              " TaggedDocument(words=['avis', 'faut', 'entraîn', 'prépar', 'bien', 'épreuv', 'sort'], tags=None),\n",
              " TaggedDocument(words=['voyageur', 'pai', 'dorm', 'pêcheur'], tags=None),\n",
              " TaggedDocument(words=['hi', 'soir', 'travaill', 'minuit'], tags=None),\n",
              " TaggedDocument(words=['entendr', 'adress', 'ellénor', 'question', 'indifférent'], tags=None),\n",
              " TaggedDocument(words=['ex', 'président', 'républ', 'win', 'myint', 'inculp', 'respect', 'restrict', 'li', 'coronavirus', 'accus', 'enfreint', 'constitu', 'indiqu', 'afp', 'avocat', 'khin', 'maung', 'zaw'], tags=None),\n",
              " TaggedDocument(words=['rav', 'comtess', 'retrouv', 'souvenir', 'jeuness', 'compar', 'sensat', 'actuel'], tags=None),\n",
              " TaggedDocument(words=['résultat', 'larg', 'inférieur', 'déchet', 'ménager', 'forment', 'grand', 'major', '2', 'million', 'ton', 'déchet', 'électron', 'produit', 'anné', 'franc', 'agenc', 'environ', 'maîtris', 'énerg', 'adem'], tags=None),\n",
              " TaggedDocument(words=['50', 'an', 'vieux', 'entrepris', 'tranch', 'chasseux', 'têt', 'catherin', 'euvrard', 'sex', 'survitamin'], tags=None),\n",
              " TaggedDocument(words=['oui', 'grand', 'soleil', 'commenc', 'réflech', 'projet', 'vacanc'], tags=None),\n",
              " TaggedDocument(words=['lev', 'heur'], tags=None),\n",
              " TaggedDocument(words=['port', 'chien', 'couru', 'flech', 'extérieur'], tags=None),\n",
              " TaggedDocument(words=['esprit', 'hiv', 'déclench', 'tempêt', 'décid'], tags=None),\n",
              " TaggedDocument(words=['région', 'où', 'enfant', 'à', 'écol', 'mercred'], tags=None),\n",
              " TaggedDocument(words=['obstin', 'gard', 'rên', 'entrepris', 'occup', 'post', 'administr', 'sieg', 'élect'], tags=None),\n",
              " TaggedDocument(words=['développ', 'technolog', 'perm', 'augment', 'import', 'product', 'soulag', 'homm', 'tâch', 'ingrat', 'pourt', 'travail', 'occup', 'larg', 'plac', 'existent'], tags=None),\n",
              " TaggedDocument(words=['oui'], tags=None),\n",
              " TaggedDocument(words=['soeur', 'habit', 'vill'], tags=None),\n",
              " TaggedDocument(words=['conséquent', 'vieil', 'ralent', 'croissanc', 'économ', 'manqu', 'main', 'oeuvr', 'défic', 'invest', 'surcroît', 'dépens', 'social'], tags=None),\n",
              " TaggedDocument(words=['bateau', 'avion', 'moyen', 'transport', 'terrestr'], tags=None),\n",
              " TaggedDocument(words=['supérior', 'scolair', 'fill', 'enseign', 'reproduisent', 'clich', 'sexist', 'favoris', 'inconscient', 'garçon'], tags=None),\n",
              " TaggedDocument(words=['rappel', 'propos', 'ministr', 'tenus', 'congres', 'révis', 'constitutionnel', 'parit', 'port', 'mod', 'scrutin', 'mani', 'général', 'insist', 'particuli', 'élect', 'législ', 'guy', 'cabanel', 'rapporteur', 'sénat', 'regret', 'text', 'adopt', 'assembl', 'national', 'dément', 'propos', 'proced', 'manipul', 'mod', 'scrutin', 'municipal'], tags=None),\n",
              " TaggedDocument(words=['lign', 'ensuit', 'diploïd', 'moyen', 'trait', 'chimiqu', 'fertil'], tags=None),\n",
              " TaggedDocument(words=['demand', 'livr', 'impress', 'primit', 'fougueux', 'jettent', 'âme', 'spher', 'commun', 'inspirent', 'dédain', 'objet', 'environnent'], tags=None),\n",
              " TaggedDocument(words=['aut', 'révolu', 'attendu', 'sign', 'mort', 'livr', 'papi'], tags=None),\n",
              " TaggedDocument(words=['vois', 'incompatibl', 'enseign', 'valeur', 'temp', 'nouvel', 'techniqu'], tags=None),\n",
              " TaggedDocument(words=['ressembl', 'scienc', 'fiction', 'pourt', 'claytron', 'appel', 'devr', 'facil', 'réalis', 'fabriqu', 'moléculair', 'nanotechnolog', 'situ', 'bien', 'niveau', 'nanometr'], tags=None),\n",
              " TaggedDocument(words=['voilà', 'an', 'proviseur', 'discret'], tags=None),\n",
              " TaggedDocument(words=['bureau', 'bibliothequ', 'sall', 'dessin'], tags=None),\n",
              " TaggedDocument(words=['phénomen', 'sourc', 'stress', 'répandu', 'moiti', 'person', 'étudi', 'perçoivent', 'signal', 'fantôm', 'fois', 'semain'], tags=None),\n",
              " TaggedDocument(words=['attaqu', 'impun', 'reper', 'culturel', 'temporel', 'fort', 'jour'], tags=None),\n",
              " TaggedDocument(words=['récent', 'synthes', 'recherch', 'men', 'grand', 'usager', 'smartphon', 'réseau', 'social', 'chercheur', 'mis', 'évident', 'grand', 'probabl', 'souffr', 'problem', 'psycholog', 'anxiet', 'dépress', 'addict'], tags=None),\n",
              " TaggedDocument(words=['tribus', 'indien', 'découvrent', 'massacr', 'amer', 'détour', 'histoir', 'autor', 'montan', 'proposent', 'profit', 'approvision', 'viand'], tags=None),\n",
              " TaggedDocument(words=['paysan', 'têt', 'queu', 'port', 'form', 'humain', 'caqueux', 'march', 'batt', 'fusil', 'allum', 'pip'], tags=None),\n",
              " TaggedDocument(words=['tet', 'embarrass', 'humili', 'rencontr', 'femm', 'trait', 'enfant'], tags=None),\n",
              " TaggedDocument(words=['candid', 'enfuit', 'vit', 'villag', 'apparten', 'bulgar', 'héros', 'abar', 'trait'], tags=None),\n",
              " TaggedDocument(words=['tourn', '3d', 'réalis', 'lwitley', 'nouvel', 'épisod', 'intergalact', 'foison', 'don', 'vit', 'migrain'], tags=None),\n",
              " TaggedDocument(words=['vi', 'quotidien', 'écol', 'copain', 'clair', 'franc', 'emport'], tags=None),\n",
              " TaggedDocument(words=['irland', 'vit', 'famill', 'bout', 'semain', 'phras', 'anglais'], tags=None),\n",
              " TaggedDocument(words=['semain', 'lev', 'heur', 'matin', 'mar', 'heur'], tags=None),\n",
              " TaggedDocument(words=['jour', 'ressembl', 'nuit'], tags=None),\n",
              " TaggedDocument(words=['envi', 'savoir', 'comprendr', 'détendr'], tags=None),\n",
              " TaggedDocument(words=['tour', 'eiffel', 'situ', 'champ', 'mar', 'parc', 'viennent', 'promen', 'famill', 'amis'], tags=None),\n",
              " TaggedDocument(words=['obtenu', 'travail', 'opiniâtr', 'milieu', 'vi', 'dissip', 'succes', 'distingu', 'compagnon', 'étud', 'concevoir', 'per', 'esper', 'probabl', 'fort', 'exager'], tags=None),\n",
              " TaggedDocument(words=['pleur', 'fois'], tags=None),\n",
              " TaggedDocument(words=['schleiermach', 'hegel', 'sent', 'vit', 'natur', 'humain', 'besoin', 'connaiss', 'divines1', 'lient', 'ailleur', 'exigent', 'moral', 'religion', 'tomb', 'ciel', 'astre'], tags=None),\n",
              " TaggedDocument(words=['symbol', 'fêt', 'autour', 'réun', 'célebr', 'noël'], tags=None),\n",
              " TaggedDocument(words=['pudeur', 'défend', 'voir', 'lam', 'nu'], tags=None),\n",
              " TaggedDocument(words=['pourt', '2006', 'choc', 'démograph', 'rud'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'blanc', 'neig', 'noir', 'nuit'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'trop', 'chaud', 'ennui'], tags=None),\n",
              " TaggedDocument(words=['numéro', 'epic', 'nom', 'vient', 'sort', 'livr', 'art', 'magazin', 'revu', 'propos', 'racont', 'mond', 'photos', 'récit'], tags=None),\n",
              " TaggedDocument(words=['siecl', 'auparav', 'empir', 'mongol', 'transform', 'temp', 'rout', 'soi', 'immens', 'construct', 'polit', 'explos', 'échang', 'méditerran', 'japon', 'pass', 'insulind', 'meilleur', 'papi', 'imprimer', 'pir', 'pest', 'noir', 'poudr', 'canon'], tags=None),\n",
              " TaggedDocument(words=['55', 'an', 'furent', 'petit', 'franc', 'babill', 'babyboom', 'guerr', 'représentent', 'aujourd', '16', 'million', 'compatriot', '20', 'popul'], tags=None),\n",
              " TaggedDocument(words=['espac', 'socialis', 'temporair', 'représent', 'centr', 'format', 'voyon', 'apparaîtr', 'form', 'convergent', 'linguist', 'identifient', 'statut', 'position', 'déplac', 'discurs', 'mod', 'convergent'], tags=None),\n",
              " TaggedDocument(words=['constat', 'simpl', 'collect', 'inform', 'grand', 'part', 'confi', 'ordin', 'demand', 'élev', 'mémoris', 'coeur', 'don', 'facil', 'retrouv', 'internet'], tags=None),\n",
              " TaggedDocument(words=['âgé'], tags=None),\n",
              " TaggedDocument(words=['effectu', 'petit', 'pression', 'dos', 'pouc'], tags=None),\n",
              " TaggedDocument(words=['soir', 'mangeon', 'poisson', 'pomm', 'terr', 'dîn'], tags=None),\n",
              " TaggedDocument(words=['aspect', 'hétéroclit'], tags=None),\n",
              " TaggedDocument(words=['automn', 'temp', 'serpent', 'dorm', 'terr', 'berg', 'entend', 'pet', 'bruit', 'lev', 'têt', 'voir', 'caus'], tags=None),\n",
              " TaggedDocument(words=['pourt', 'évoqu', 'histoir', 'doulour'], tags=None),\n",
              " TaggedDocument(words=['veut'], tags=None),\n",
              " TaggedDocument(words=['avion', 'ramen', 'irak', 'lund', 'matin', '8', 'mar', 'pap', 'françois', 'comment', 'visit', 'intens', 'plein', 'gest', 'rencontr', 'symbol', 'jour', 'cour', 'conférent', 'press'], tags=None),\n",
              " TaggedDocument(words=['dommag', 'fois', 'aim', 'bien', 'pos', 'question', 'demand', 'conseil'], tags=None),\n",
              " TaggedDocument(words=['non', 'mang', 'goût', 'class'], tags=None),\n",
              " TaggedDocument(words=['voisin', 'recueil', 'beau', 'pet', 'chat', 'abandon'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'chanc', 'pouvoir', 'mang', 'légum', 'frais', 'jardin', 'jour', 'salad', 'tomat', 'carott', 'chou', 'rad', 'pomm', 'terr'], tags=None),\n",
              " TaggedDocument(words=['vieux', 'baro', 'val', 'zéro', 'interromp', 'remord'], tags=None),\n",
              " TaggedDocument(words=['comtess', 'pleur', 'joi', 'angoiss'], tags=None),\n",
              " TaggedDocument(words=['brigitt', 'muni', 'appartient', 'homm', 'point', 'intimid', 'séduir', 'puissanc', 'robot', 'point', 'perdr', 'sen', 'spécif', 'compétent', 'pur', 'humain', 'illog', 'apparent', 'propr', 'émot', 'sensibil', 'imagin', 'symbol', 'facult', 'inimit', 'machin', 'programm', 'simul', 'empath'], tags=None),\n",
              " TaggedDocument(words=['derni', 'enquêt', 'valeur', 'franc', 'dessin', 'pay', 'soucieux', 'libert', 'spher', 'priv', 'égal', 'domain', 'social'], tags=None),\n",
              " TaggedDocument(words=['tanguy', 'veut', 'aller', 'mer', 'mois', 'prochain'], tags=None),\n",
              " TaggedDocument(words=['pâqu', 'dat', 'fix', 'dimanch', '22', 'mar', '25', 'avril'], tags=None),\n",
              " TaggedDocument(words=['chef', 'major', 'sénat', 'chuck', 'schum', 'affirm', 'mard', 'compt', 'suffis', 'voix', '51', 'approuv', 'projet', 'loi', 'ici', 'fin', 'semain'], tags=None),\n",
              " TaggedDocument(words=['aliment', 'jou', 'rôl', 'apparit', 'troubl', 'mental'], tags=None),\n",
              " TaggedDocument(words=['faut', 'réflech', 'recherch', 'conséquent', 'social', 'vieil', 'limit'], tags=None),\n",
              " TaggedDocument(words=['bacter', 'vivon', 'symbios', 'ami', 'apporton', 'mang', 'contrepart', 'occupent', 'prédiger', 'aliment', 'assimil'], tags=None),\n",
              " TaggedDocument(words=['jul', 'beaucoup', 'bruit', 'port'], tags=None),\n",
              " TaggedDocument(words=['moment', 'appel', 'parent', 'prendr', 'nouvel'], tags=None),\n",
              " TaggedDocument(words=['préserv', 'fond', 'croiss', 'referm', 'sachet', 'soigneux', 'ouvertur'], tags=None),\n",
              " TaggedDocument(words=['demain', 'prévoit', 'fair', 'promenad', 'quarti', 'petit', 'franc', 'paraît', 'beau', 'strasbourg'], tags=None),\n",
              " TaggedDocument(words=['vient', 'fêt', 'soir'], tags=None),\n",
              " TaggedDocument(words=['corp', 'humain', 'comprend', 'têt', 'tronc', 'membr'], tags=None),\n",
              " TaggedDocument(words=['côt', 'géner', 'nouveau', 'besoin', 'aliment', 'narciss', 'adolescent', 'jeun', 'adult', 'sensibl', 'besoin', 'popular', 'côt', 'provoqu', 'nombr', 'frustrat'], tags=None),\n",
              " TaggedDocument(words=['entrepris', 'vendent', 'été', 'littéral', 'dévalis', 'explos', 'command', 'téléphon', 'lign'], tags=None),\n",
              " TaggedDocument(words=['enferm', 'petit', 'boît', 'bois', 'découvert', 'tapiss', 'roug', 'conten', 'chais', 'couleur', 'rapproch', 'pein', 'gliss'], tags=None),\n",
              " TaggedDocument(words=['sav'], tags=None),\n",
              " TaggedDocument(words=['bon', 'adress', 'amateur', 'viand', 'charcuter'], tags=None),\n",
              " TaggedDocument(words=[], tags=None),\n",
              " TaggedDocument(words=['facil'], tags=None),\n",
              " TaggedDocument(words=['nom', 'indiqu', 'fromag', 'aop', 'appel', 'origin', 'proteg'], tags=None),\n",
              " TaggedDocument(words=['cuisini', 'laqu', 'coch', 'cheval', 'part', 'côm', 'veil', 'voyag', 'jour', 'milan', 'marquis', 'trouv', 'voitur', 'ordre', 'dîn', 'couvert'], tags=None),\n",
              " TaggedDocument(words=['exempl', 'connexion', 'permanent', 'offre', 'person', 'ennui', 'vi', 'stimul', 'divert', 'uniqu', 'court', 'term'], tags=None),\n",
              " TaggedDocument(words=['écout', 'professeur', 'étudi'], tags=None),\n",
              " TaggedDocument(words=['cheveux', 'raid'], tags=None),\n",
              " TaggedDocument(words=['revu', 'noi', 'carbur'], tags=None),\n",
              " TaggedDocument(words=['propos', 'benoît', 'hamon', 'tenus', 'jdd', 'mi', 'juillet'], tags=None),\n",
              " TaggedDocument(words=['étud', 'récent', 'montr', 'cyclist', 'demandeur', 'sécur', 'station', 'vélo', 'abord', 'gar', 'particuli'], tags=None),\n",
              " TaggedDocument(words=['multipl', 'nouvel', 'technolog', 'fair', 'perdr', 'têt'], tags=None),\n",
              " TaggedDocument(words=['aussitôt', 'registr', 'commerc', 'reçu', 'dossi', 'modif'], tags=None),\n",
              " TaggedDocument(words=['crois', 'contrat', 'sign', 'pourron', 'commenc', 'travaill', 'vit'], tags=None),\n",
              " TaggedDocument(words=['flatter', 'éman', 'jam', 'grand', 'âme', 'apanag', 'petit', 'esprit', 'réuss', 'rapetiss', 'mieux', 'entrer', 'spher', 'vital', 'autour', 'gravitent'], tags=None),\n",
              " TaggedDocument(words=['exist', 'fois', 'consensus', 'larg', 'conclus', 'organ', 'scientif', 'collégial', 'international', 'giec', 'fair', 'fac', 'déregl', 'climat', 'imper', 'décarbon', 'économ'], tags=None),\n",
              " TaggedDocument(words=['gratitud', 'anim', 'kassák'], tags=None),\n",
              " TaggedDocument(words=['presbyter', 'situ', 'églis', 'commun', 'cimeti'], tags=None),\n",
              " TaggedDocument(words=['rend', 'urgent', 'extérieur'], tags=None),\n",
              " TaggedDocument(words=['chanc'], tags=None),\n",
              " TaggedDocument(words=['acces', 'moyen', 'transport', 'mécanis', 'travail', 'sédentaris', 'augment', 'loisir', 'passif', 'cinem', 'télévis', 'jouent', 'certain', 'rôledan', 'chang', 'observ', 'pay', 'voi', 'développ'], tags=None),\n",
              " TaggedDocument(words=['patt'], tags=None),\n",
              " TaggedDocument(words=['femm', 'prépar', 'sauc', 'pain', 'dîn'], tags=None),\n",
              " TaggedDocument(words=['passon', 'temp', 'établ', 'désétabl'], tags=None),\n",
              " TaggedDocument(words=['arriv', 'moment', 'départ', 'instant', 'suiv', 'ave', 'mari', 'fabric', 'frapp', 'présag'], tags=None),\n",
              " TaggedDocument(words=['aim', 'beaucoup', 'voix', 'voix', 'grav', 'attend', 'fill', 'frêl'], tags=None),\n",
              " TaggedDocument(words=['directric', 'patrici', 'rodrigu', 'élev', 'grand', 'section', 'maternel', 'lassent', 'spectacl'], tags=None),\n",
              " TaggedDocument(words=['géner', 'décrisp', 'devenu', 'presqu', 'banal', 'refair', 'vi', 'larg', 'pass', 'âge', 'retrait', 'cour', 'nouveau', 'amour', 'conservent', 'log'], tags=None),\n",
              " TaggedDocument(words=['valoris', 'solidar', 'moyen', 'opinion', 'empêch', 'franc', 'societ', 'défianc', 'pet', 'quart', 'person', 'interrog', 'déclarent', 'prêt', 'accord', 'spontan', 'confianc'], tags=None),\n",
              " TaggedDocument(words=['douceur', 'contrast', 'températur', 'sibérien', 'semain'], tags=None),\n",
              " TaggedDocument(words=['problem', 'fair'], tags=None),\n",
              " TaggedDocument(words=['miaou', 'veux', 'rentr', 'maison', 'jul'], tags=None),\n",
              " TaggedDocument(words=['délinqu', 'jeun', 'minor'], tags=None),\n",
              " TaggedDocument(words=['issu', 'élect', 'compt', 'campagn', 'retrac', 'ensembl', 'recet', 'dépens', 'électoral', 'dépos', 'aupres', 'commiss', 'national', 'compt', 'campagn', 'financ', 'polit', 'contrôl', 'vérac'], tags=None),\n",
              " TaggedDocument(words=['eût', 'quelquefois', 'révolt', 'secret', 'mêl', 'attach', 'passion', 'tendr', 'montr', 'rend', 'sort', 'importun'], tags=None),\n",
              " TaggedDocument(words=['monstr', 'cach', 'lit'], tags=None),\n",
              " TaggedDocument(words=['enfant', 'tair', 'signal', 'fair'], tags=None),\n",
              " TaggedDocument(words=['fois', 'grand', 'forêt'], tags=None),\n",
              " TaggedDocument(words=['malnutrit', 'apparaît', 'aujourd', 'résultat', 'organis', 'inadéquat', 'system', 'économ', 'polit'], tags=None),\n",
              " TaggedDocument(words=['préposit', 'signif', 'contr', 'volont', 'quelqu'], tags=None),\n",
              " TaggedDocument(words=['tabl', 'rond', 'bruno', 'bonnel', 'pdg', 'robopol', 'societ', 'français', 'spécialis', 'robot', 'personnel', 'richard', 'castel', 'commissair', 'artist', 'exposit', 'art', 'robo', 'tiqu', 'cit', 'scienc', 'industr', 'paris', 'brigitt', 'muni', 'enseign', 'chercheux'], tags=None),\n",
              " TaggedDocument(words=['apprit', 'cour', 'lutt', 'saut', 'lanc', 'loin', 'lourd', 'pierr', 'franch', 'mur', 'frapp', 'main', 'dress', 'jeun', 'cheval', 'franch', 'nag', 'rivi'], tags=None),\n",
              " TaggedDocument(words=['grâc', 'anecdot', 'proviseur', 'enorgueil', 'envoi', 'aucun', 'bacheli', 'fili', 'bouch'], tags=None),\n",
              " TaggedDocument(words=['beau', 'monsieur', 'berg', 'vrai', 'dit'], tags=None),\n",
              " TaggedDocument(words=['format', 'sant', 'relat', 'social', 'part', 'dimens', 'immatériel', 'bien', 'englobent', 'cadr', 'légal', 'institutionnel', 'particip', 'citoyen', 'vi', 'polit', 'assur', 'sécur', 'physiqu', 'person'], tags=None),\n",
              " TaggedDocument(words=['élev', 'enfant', 'eus', 'comt', 'p', 'auster', 'excess'], tags=None),\n",
              " TaggedDocument(words=['trêv', 'attendu', 'vient', 'adouc', 'cont', 'coeur', 'endolor', 'esseul'], tags=None),\n",
              " TaggedDocument(words=['résist', 'plais', 'schtroumpf', 'text', 'remplac', 'verb', 'action', 'particip', 'pass', 'verb', 'schtroumpf', 'correct', 'accord', 'bien', 'sûr'], tags=None),\n",
              " TaggedDocument(words=['passon', 'bon', 'moment', 'jou', 'ensembl', 'jardin'], tags=None),\n",
              " TaggedDocument(words=['allait', 'touch', 'quarti', 'petit', 'pension', 'pauvr', 'veuv', 'général', 'cisalpin', 'prêt', 'sequin', 'richissim', 'marquis', 'del', 'dongo'], tags=None),\n",
              " TaggedDocument(words=['début'], tags=None),\n",
              " TaggedDocument(words=['croi', 'aut', 'mond', 'besoin', 'apprendr', 'toler'], tags=None),\n",
              " TaggedDocument(words=['mont', 'barqu', 'enfant', 'croi', 'précipit', 'grand', 'danger', 'beau', 'côt', 'action', 'exempl', 'per', 'récit', 'dévot', 'ave', 'mari'], tags=None),\n",
              " TaggedDocument(words=['vacanc'], tags=None),\n",
              " TaggedDocument(words=['broch', 'pratiqu', 'accumul', 'petit', 'boléros'], tags=None),\n",
              " TaggedDocument(words=['part', 'cent', 'prompt', 'renfort', 'vîm', 'arriv', 'port'], tags=None),\n",
              " TaggedDocument(words=['illus', 'vrai', 'jam', 'immuabl'], tags=None),\n",
              " TaggedDocument(words=['ensuit', 'sortion', 'promenad', 'parc', 'retrouv', 'amis'], tags=None),\n",
              " TaggedDocument(words=['paroi', 'rocheux', 'escarp', 'petit', 'maison', 'blanch', 'caban', 'roug', 'pêcheur', 'form', 'colli', 'perl'], tags=None),\n",
              " TaggedDocument(words=['mar', 'laurent', 'furent', 'téléphon', 'jour', 'premi', 'heur', 'aub'], tags=None),\n",
              " TaggedDocument(words=['achet', 'antiqu'], tags=None),\n",
              " TaggedDocument(words=['temp', 'migr', 'afriqu', 'attend', 'prochain', 'été'], tags=None),\n",
              " TaggedDocument(words=['oeuf', 'pondu', 'vendred', 'saint', 'préserv', 'foudr', 'mang', 'garant', 'fievr', 'rag'], tags=None),\n",
              " TaggedDocument(words=['sécheress', 'connaît', 'actuel', 'franc', 'résult', 'météorolog', 'défavor', 'découl', 'polit', 'eau', 'tm', 'archaïqu'], tags=None),\n",
              " TaggedDocument(words=['international', 'business', 'machin', 'corpor', 'connu', 'sigl', 'ibm', 'societ', 'multinational', 'américain', 'présent', 'domain', 'matériel', 'informat', 'logiciel', 'servic', 'informat'], tags=None),\n",
              " TaggedDocument(words=['espec', 'présentent', 'adapt', 'chromat', 'vi', 'eau', 'profond', 'grâc', 'variat', 'rapport', 'phycoérythrin', 'phycocyanin'], tags=None),\n",
              " TaggedDocument(words=['saint', 'homm'], tags=None),\n",
              " TaggedDocument(words=['question', 'vi', 'mort'], tags=None),\n",
              " TaggedDocument(words=['esper', 'rendu', 'indulgent', 'beaucoup', 'faut', 'commis'], tags=None),\n",
              " TaggedDocument(words=['sall', '33'], tags=None),\n",
              " TaggedDocument(words=['prendr', 'steak', 'frit'], tags=None),\n",
              " TaggedDocument(words=['mang'], tags=None),\n",
              " TaggedDocument(words=['commenc', 'mois', 'prépar', 'pet', 'pet', 'transit'], tags=None),\n",
              " TaggedDocument(words=['expédit', 'forêt'], tags=None),\n",
              " TaggedDocument(words=['bord', 'vaisseau', 'rosco', 'capitain', 'jim', 'mission', 'sauv', 'univer', 'terror', 'imprudent', 'décongel'], tags=None),\n",
              " TaggedDocument(words=['plupart', 'observ', 'dev', 'paraîtr', 'extrêm', 'imprudent', 'danger', 'ger', 'entrepris'], tags=None),\n",
              " TaggedDocument(words=['eut', 'lu', 'correspond', 'sort', 'fair', 'promenad'], tags=None),\n",
              " TaggedDocument(words=['berg', 'pens', 'femm', 'descend', 'montagn', 'vit', 'peur', 'grond', 'rest', 'absent'], tags=None),\n",
              " TaggedDocument(words=['espec', 'frénes', 'inform'], tags=None),\n",
              " TaggedDocument(words=['anné', '2', '500', 'franc', 'créent', 'gît', 'rural', 'aventur', 'pourt', 'risqu'], tags=None),\n",
              " TaggedDocument(words=['épin', 'déchir', 'pied', 'rameau', 'pointus', 'bless', 'visag', 'souffr', 'tour', 'tour', 'écras', 'soleil', 'bis', 'glac', 'pens', 'mour', 'faim', 'soif', 'fatigu'], tags=None),\n",
              " TaggedDocument(words=['cas'], tags=None),\n",
              " TaggedDocument(words=['allur', 'don', 'impress', 'séduir'], tags=None),\n",
              " TaggedDocument(words=['tourment', 'femm', 'beau', 'monsieur', 'berg', 'racont', 'arriv'], tags=None),\n",
              " TaggedDocument(words=['trouv', 'occurrent', 'googl'], tags=None),\n",
              " TaggedDocument(words=['unilingu', 'signifi', 'correspond', 'signifi'], tags=None),\n",
              " TaggedDocument(words=['bon', 'humeur', 'fin', 'charad', 'habituel', 'soir'], tags=None),\n",
              " TaggedDocument(words=['fabric', 'prit', 'post', 'pass', 'saint', 'gothard', 'voyag', 'fut', 'rapid', 'entra', 'franc', 'pontarli'], tags=None),\n",
              " TaggedDocument(words=['endroit', 'magnif', 'baignad', 'escalad'], tags=None),\n",
              " TaggedDocument(words=['architect'], tags=None),\n",
              " TaggedDocument(words=['répet'], tags=None),\n",
              " TaggedDocument(words=['nécessair', 'soeint', 'conscient', 'import', 'écolog'], tags=None),\n",
              " TaggedDocument(words=['chanceli', 'autrichien', 'critiqu', 'fonction', 'agenc', 'européen', 'médic', 'trop', 'lent', 'approuv', 'vaccin', 'conduit', 'goulot', 'étrangl', 'chaîn', 'product', 'societ', 'pharmaceut', 'ajout', 'der', 'standard'], tags=None),\n",
              " TaggedDocument(words=['pourt', 'gest', 'familli', 'rappel', 'quotidien', 'construct', 'inégalitair', 'mond', 'initi', 'xve', 'siecl'], tags=None),\n",
              " TaggedDocument(words=['per', 'point', 'final'], tags=None),\n",
              " TaggedDocument(words=['acteur', 'établ', 'relat', 'triurn', 'impliqu', 'aspect', 'énerget', 'émotionnel', 'computationnel'], tags=None),\n",
              " TaggedDocument(words=['appris', 'nouvel', 'entretu', 'rapport', 'quotidien', 'économ', 'américain'], tags=None),\n",
              " TaggedDocument(words=['figur', 'pauvr', 'entass', 'log', 'insalubr', 'plafond', 'menac', 'effondr', 'moment'], tags=None),\n",
              " TaggedDocument(words=['chien', 'apport', 'beaucoup', 'bonheur'], tags=None),\n",
              " TaggedDocument(words=['histoir', 'berg', 'fois', 'montag', 'mouton', 'entend', 'pet', 'bruit'], tags=None),\n",
              " TaggedDocument(words=['dépeign', 'longu', 'process', 'cavali', 'adolescent', 'jeun', 'fill', 'grav', 'chant', 'collin', 'sacr', 'templ', 'couron', 'collin', 'sanctuair', 'grandios', 'délicat', 'abrit', 'statu', 'dieux', 'déess', 'bel', 'devin', 'non', 'point', 'vulgair', 'imag', 'bien', 'preuv', 'visibl', 'divin'], tags=None),\n",
              " TaggedDocument(words=['mour', 'emportent', 'savoir', 'traditionnel', 'environ'], tags=None),\n",
              " TaggedDocument(words=['mot', 'robot', 'été', 'invent', 'auteur', 'tchequ', 'karel', 'capek', 'piec', 'rossum', 'universal', 'robot', 'r', 'u', 'r', 'jou', '1920', 'met', 'scen', 'homm', 'décérebr', 'pren', 'plac', 'ouvri', 'usin'], tags=None),\n",
              " TaggedDocument(words=['préserv', 'affair', 'urgent'], tags=None),\n",
              " TaggedDocument(words=['éventr', 'croût', 'mord', 'brûl', 'ret', 'viv', 'pomm', 'terr', 'roul', 'quelquefois', 'genoux', 'main', 'lest', 'rattrap', 'temp'], tags=None),\n",
              " TaggedDocument(words=['analys', 'effectu', 'recherch', 'anticorp', 'dépistag', 'direct', 'agent', 'pathogen'], tags=None),\n",
              " TaggedDocument(words=['caracter', 'temporair', 'remplac', 'caus', 'accept', 'fonction', 'gouvernemental', 'appliqu', 'derni', 'candidat', 'devenu', 'sénateur', 'conform', 'ordre', 'list'], tags=None),\n",
              " TaggedDocument(words=['lund', 'retourn', 'écol'], tags=None),\n",
              " TaggedDocument(words=['advint', 'sort', 'forêt', 'lion', 'fut', 'pris', 'ret', 'rug', 'purent', 'défair'], tags=None),\n",
              " TaggedDocument(words=['télévendeur', 'travaill', 'temp', 'plein', 'temp', 'partiel', 'compl', 'activ'], tags=None),\n",
              " TaggedDocument(words=['premi', 'traval', 'import', 'réalis', 'servic', 'duc', 'ludovic', 'sforz', 'milan'], tags=None),\n",
              " TaggedDocument(words=['hi', 'décid', 'offrir', 'bel', 'journ'], tags=None),\n",
              " TaggedDocument(words=['pratiqu', 'bon', 'sen', 'épargn', 'analys', 'approfond', 'raison', 'usager', 'fort', 'attach', 'internet', 'réseau', 'social', 'smartphon', 'craint', 'pouvoir', 'utilis'], tags=None),\n",
              " TaggedDocument(words=['derni', 'ministr', 'éduc', 'national', 'souhait', 'durc', 'interdict', 'téléphon', 'portabl', 'colleg', 'exist', 'pratiqu', 'suffis', 'appliqu', 'aucun', 'sanction', 'prévu'], tags=None),\n",
              " TaggedDocument(words=['support'], tags=None),\n",
              " TaggedDocument(words=['condit', 'victoir', 'object', 'dépendent', 'typ', 'cart', 'jou'], tags=None),\n",
              " TaggedDocument(words=['chômag', 'moment'], tags=None),\n",
              " TaggedDocument(words=['allé', 'fois', 'thalassothérap', 'an'], tags=None),\n",
              " TaggedDocument(words=['jour', 'rentr', 'colleg', 'pierr', 'connaiss', 'nouvel', 'élev', 'class'], tags=None),\n",
              " TaggedDocument(words=['beaucoup', 'jeun', 'établ', 'scolair', 'gagn', 'libert', 'autonom'], tags=None),\n",
              " TaggedDocument(words=['nom', 'mot', 'tradit', 'demandent', 'autochton', 'conforment'], tags=None),\n",
              " TaggedDocument(words=['envoi', 'messag', 'amis', 'soir', 'couch'], tags=None),\n",
              " TaggedDocument(words=['cas', 'exempl', 'agriculteur'], tags=None),\n",
              " TaggedDocument(words=['oppos', 'projet', 'rassembl', 'dep', 'interdict', 'manifest'], tags=None),\n",
              " TaggedDocument(words=['motocyclet', 'cour', 'désign', 'abrévi', 'moto', 'véhicul', 'motoris', 'carrosser', 'rou', 'monotrac', 'pouv', 'équip', 'sid'], tags=None),\n",
              " TaggedDocument(words=['direct', 'bougon', 'jo', 'manchin', '73', 'an', 'discret', 'médiat', 'contrast', 'perruqu', 'tenu', 'color', 'kyrsten', 'sinem', '44', 'an', 'candidat', 'sénat', 'ouvert', 'bisexuel', '2018'], tags=None),\n",
              " TaggedDocument(words=['égard', 'exist', 'avantag', 'techniqu', 'enfant', 'breton', 'apprendr', 'breton'], tags=None),\n",
              " TaggedDocument(words=['mar', 'enfant', 'fill', 'an', 'garçon', 'an'], tags=None),\n",
              " TaggedDocument(words=['fus', 'accueil', 'cour', 'curios', 'inspir', 'naturel', 'étrang', 'vient', 'rompr', 'cercl', 'monoton', 'étiquet'], tags=None),\n",
              " TaggedDocument(words=['décidé', 'peindr', 'mur', 'jaun', 'install', 'piano'], tags=None),\n",
              " TaggedDocument(words=['présent', 'soph', 'parl', 'expos', 'oeuvr', 'ventooz', 'art'], tags=None),\n",
              " TaggedDocument(words=['avez', 'marionnet', 'fil', 'manipul', 'marionnet', 'fil', 'reli', 'anim'], tags=None),\n",
              " TaggedDocument(words=['ressourc', 'perspect', 'travail', 'entend', 'processus', 'relationnel', 'variabl', 'objet', 'usager', 'ret', 'bien', 'servic', 'vari'], tags=None),\n",
              " TaggedDocument(words=['fois', 'catastroph', 'écolog', 'produit', 'région'], tags=None),\n",
              " TaggedDocument(words=['pain'], tags=None),\n",
              " TaggedDocument(words=['parut', 'inquiet', 'compren', 'mot', 'quibus'], tags=None),\n",
              " TaggedDocument(words=['question', 'point', 'vu'], tags=None),\n",
              " TaggedDocument(words=['anné', 'confiser', 'décor', 'vitrin', 'paquet', 'gâteau', 'effig', 'citrouill', 'sorci', 'éven', 'visibl', 'hexagon'], tags=None),\n",
              " TaggedDocument(words=['demand', 'aim', 'fass', 'tard'], tags=None),\n",
              " TaggedDocument(words=['anné', 'attent', 'eut', 'joi', 'inexprim', 'voir', 'troup', 'autrichien', 'rentr', 'milan'], tags=None),\n",
              " TaggedDocument(words=['langu', 'viv', 'franc', 'enseign', 'langu', 'mort'], tags=None),\n",
              " TaggedDocument(words=['pay', 'défavoris', 'voient', 'situat', 'alimentair', 'dégrad', 'inexor'], tags=None),\n",
              " TaggedDocument(words=['sort', 'eus', 'pris', 'clé'], tags=None),\n",
              " TaggedDocument(words=['musiqu', 'don', 'mal', 'têt'], tags=None),\n",
              " TaggedDocument(words=['général', 'lou', 'maison', 'campagn'], tags=None),\n",
              " TaggedDocument(words=['pass'], tags=None),\n",
              " TaggedDocument(words=['allez', 'pilot', 'fichu', 'avion', 'amen', 'amer', 'sud'], tags=None),\n",
              " TaggedDocument(words=['utilis', 'mot', 'esclav', 'revient', 'consider', 'chos', 'machin', 'capac', 'déduct', 'connexion', 'développ', 'forc', 'mécan', 'puiss', 'précis', 'micrometr', 'robot', 'machin', 'servic', 'homm'], tags=None),\n",
              " TaggedDocument(words=['pach', 'admir'], tags=None),\n",
              " TaggedDocument(words=['jeu', 'japon', 'amusent', 'tremp', 'bol', 'porcelain', 'rempl', 'eau', 'petit', 'morceau', 'papi', 'indistinct', 'pein', 'plong', 'étirent', 'contournent', 'colorent', 'différencient', 'deviennent', 'fleur', 'maison', 'personnag', 'consist', 'reconnaiss', 'fleur', 'jardin'], tags=None),\n",
              " TaggedDocument(words=['dis', 'grâc', 'forêt', 'bel'], tags=None),\n",
              " TaggedDocument(words=['parad', 'dis'], tags=None),\n",
              " TaggedDocument(words=['regard', 'tas', 'feuill'], tags=None),\n",
              " TaggedDocument(words=['consomm', 'occidental', 'prêt', 'aid', 'producteur', 'sud', 'achet', 'équit', 'consomm', 'produit', 'alimentair', 'artisanal', 'garant', 'rémuner', 'été', 'vers', 'producteur'], tags=None),\n",
              " TaggedDocument(words=['langag', 'cour', 'libert', 'renvoi', 'pouvoir', 'possed', 'homm', 'obéir', 'propr', 'volont', 'agir', 'uniqu', 'fonction', 'désir', 'indépend', 'contraint', 'pression', 'extérieur'], tags=None),\n",
              " TaggedDocument(words=['arriv', 'arbre', 'fin', 'histoir'], tags=None),\n",
              " TaggedDocument(words=['républicain', 'veulent', 'accompl', 'chos'], tags=None),\n",
              " TaggedDocument(words=['approch', 'fonction', 'tâch', 'élabor', 'lois', 'command', 'réalis', 'correct', 'tâch', 'bon', 'propriet', 'convergent', 'stabl'], tags=None),\n",
              " TaggedDocument(words=['cadr', 'enchanteur', 'nourritur', 'exquis', 'rêv', 'meilleur', 'soir', 'clôtur', 'vacanc', 'idyll'], tags=None),\n",
              " TaggedDocument(words=['déplac', 'bus', 'vélos', 'métro'], tags=None),\n",
              " TaggedDocument(words=['hongr', 'slovaqu', 'pologn', 'appel', 'russ', 'chin'], tags=None),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_train, document_test = train_test_split(documents, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "FHCdUQiEUdEr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "\n",
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(document_train)])\n",
        "document = utils.shuffle(document_train)\n",
        "model_dbow.train(documents, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)\n",
        "def vector_for_learning(model, input_docs):\n",
        "    sents = input_docs\n",
        "    targets, feature_vectors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=100)) for doc in sents])\n",
        "    return targets, feature_vectors\n",
        "\n",
        "def vector_for_pred(model, input_docs):\n",
        "    sents = input_docs\n",
        "    feature_vectors = [(model.infer_vector(doc.words, steps=100)) for doc in sents]\n",
        "    return feature_vectors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsWn3QaFRfh1",
        "outputId": "d5278849-35fa-4bdc-963a-0f4d39e5e4c3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3840/3840 [00:00<00:00, 1106266.05it/s]\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 1 : supplied example count (4800) did not equal expected count (3840)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 2 : supplied example count (4800) did not equal expected count (3840)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 3 : supplied example count (4800) did not equal expected count (3840)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 4 : supplied example count (4800) did not equal expected count (3840)\n",
            "WARNING:gensim.models.base_any2vec:EPOCH - 5 : supplied example count (4800) did not equal expected count (3840)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, X_train = vector_for_learning(model_dbow, document_train)\n",
        "y_test, X_test = vector_for_learning(model_dbow, document_test)"
      ],
      "metadata": {
        "id": "nUqmvnfRgvsA"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model on training set\n",
        "logregCV = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=0)\n",
        "logregCV.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = logregCV.predict(X_test)"
      ],
      "metadata": {
        "id": "SN39h-aYgtP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa446a5-657d-49d8-c7f6-40a00542189d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSqP0tP8iurf",
        "outputId": "28e37926-de34-4e5f-c52a-ea4f51b3ba86"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[ 98   7  11  10  23  24]\n",
            " [  3 122  11  23   1   1]\n",
            " [  7  23  88  19  14   9]\n",
            " [  4  47  17  90   4   2]\n",
            " [  8   5   9   8 103  11]\n",
            " [ 19   7   5   4  20 103]]\n",
            "ACCURACY SCORE:\n",
            "0.6292\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.6338\n",
            "\tRecall: 0.6317\n",
            "\tF1_Score: 0.6284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdocuments = vector_for_pred(model_dbow, testdocuments)\n",
        "LogRegPredCV = logregCV.predict(testdocuments)"
      ],
      "metadata": {
        "id": "tcHgsucD7uT4"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame(columns=['difficulty'])\n",
        "predictions['label'] = LogRegPredCV\n",
        "predictions['difficulty'] = predictions['label'].replace([1,2,3,4,5,6],['A1','A2','B1','B2','C1','C2'])\n",
        "predictions = predictions.drop(columns=['label'])\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_qQUJvD89jjK",
        "outputId": "35eecb0b-23d9-4da8-8f1b-507e5af06321"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     difficulty\n",
              "0            C2\n",
              "1            B2\n",
              "2            B1\n",
              "3            C1\n",
              "4            C2\n",
              "...         ...\n",
              "1195         A1\n",
              "1196         B2\n",
              "1197         C2\n",
              "1198         A1\n",
              "1199         C1\n",
              "\n",
              "[1200 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22f27f85-d27f-4b52-9ec0-ea36bd52584a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>B2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22f27f85-d27f-4b52-9ec0-ea36bd52584a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22f27f85-d27f-4b52-9ec0-ea36bd52584a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22f27f85-d27f-4b52-9ec0-ea36bd52584a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.to_csv(\"doc2vec.csv\")"
      ],
      "metadata": {
        "id": "TBI8DtBk9rXy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble TEST"
      ],
      "metadata": {
        "id": "nweY2PYTMR-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
        "#https://towardsdatascience.com/ensemble-methods-or-democracy-for-ai-bac2fa129f61\n",
        "\n",
        "#https://github.com/crownpku/text2vec"
      ],
      "metadata": {
        "id": "XqosAazDUV6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "QTryZvYfR64o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=0)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LRCV1 = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "DuXuBqthMd9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43)"
      ],
      "metadata": {
        "id": "MfGK13s7R9Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=43)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LRCV2 = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "E7GK7BVnMjMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12)"
      ],
      "metadata": {
        "id": "NXGxV-1SR91q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=12)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LRCV3 = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "8LK4dWzbM04j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=33)"
      ],
      "metadata": {
        "id": "1f5Yr1GmR-Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=33)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LRCV4 = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "T-Qhj7pCM4P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=20)"
      ],
      "metadata": {
        "id": "iAp-iBndR_Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=20)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LRCV5 = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "CypEP8yIPN8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "Fisot9okNHDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting_clf = VotingClassifier(estimators=[('LCRV1', pipe_LRCV1), ('LCRV2', pipe_LRCV2), ('LCRV3', pipe_LRCV3), ('LCRV4', pipe_LRCV4), ('LCRV5', pipe_LRCV5)], voting='soft')"
      ],
      "metadata": {
        "id": "duLSRSbpNLiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting_clf.fit(X_train, y_train) # training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUWxCkHiNgle",
        "outputId": "543cabde-cbeb-4b59-a5a8-f681304c90b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('LCRV1',\n",
              "                              Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                                              ('classifier',\n",
              "                                               LogisticRegressionCV(cv=5,\n",
              "                                                                    max_iter=1000,\n",
              "                                                                    random_state=0))])),\n",
              "                             ('LCRV2',\n",
              "                              Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                                              ('classifier',\n",
              "                                               LogisticRegressionCV(cv=5,\n",
              "                                                                    max_iter=1000,\n",
              "                                                                    random_state=43))])),\n",
              "                             ('LCRV3',\n",
              "                              Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                                              ('classifier',\n",
              "                                               LogisticRegressionCV(cv=5,\n",
              "                                                                    max_iter=1000,\n",
              "                                                                    random_state=12))])),\n",
              "                             ('LCRV4',\n",
              "                              Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                                              ('classifier',\n",
              "                                               LogisticRegressionCV(cv=5,\n",
              "                                                                    max_iter=1000,\n",
              "                                                                    random_state=33))])),\n",
              "                             ('LCRV5',\n",
              "                              Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                                              ('classifier',\n",
              "                                               LogisticRegressionCV(cv=5,\n",
              "                                                                    max_iter=1000,\n",
              "                                                                    random_state=20))]))],\n",
              "                 voting='soft')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = soft_voting_clf.predict(X_pred)\n",
        "\n",
        "predictions = pd.DataFrame(predictions,columns=['difficulty'])\n",
        "\n",
        "predictions.to_csv(\"ensembleLRCV5x5v2.csv\")"
      ],
      "metadata": {
        "id": "Py3b8tyGNtFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LinearSVC"
      ],
      "metadata": {
        "id": "o_WVta6XCOpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "y12cjmsTCamw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LinearSVC()"
      ],
      "metadata": {
        "id": "NGBc0YDfCUuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvHRi0UoCQmx",
        "outputId": "3f697241-e3e8-4e2e-cb8c-d1ec2fe0164b"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()), ('classifier', LinearSVC())])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipe.predict(X_pred)\n",
        "\n",
        "predictions = pd.DataFrame(predictions,columns=['difficulty'])\n",
        "\n",
        "predictions.to_csv(\"LinearSVC.csv\")"
      ],
      "metadata": {
        "id": "I1dm4F2GCvAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MultinomialNB"
      ],
      "metadata": {
        "id": "QKF7n6vZDHCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classifier = MultinomialNB()"
      ],
      "metadata": {
        "id": "xsa1hMGWDJmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJA-UKdYDtX5",
        "outputId": "dad0874c-6d49-46d8-e286-d0207f93042d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
              "                ('classifier', MultinomialNB())])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipe.predict(X_pred)\n",
        "\n",
        "predictions = pd.DataFrame(predictions,columns=['difficulty'])\n",
        "\n",
        "predictions.to_csv(\"MultinomialNB.csv\")"
      ],
      "metadata": {
        "id": "CbRZiCcSDvDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LRCV5 + LinearSVC + MultinomialNB"
      ],
      "metadata": {
        "id": "17FhfEtTEDn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, random_state=0)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LRCV = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "iXNAPA1QEKCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gv93BAoJgiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n"
      ],
      "metadata": {
        "id": "aXH8kzWSJA3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2 = SklearnClassifier(SVC(kernel='linear',probability=True))\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_LinearSVC = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "88UFyurEEYfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "classifier3 = MultinomialNB()\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "pipe_MultinomialNB = Pipeline([('vectorizer', tfidf),\n",
        "                 ('classifier', classifier)])"
      ],
      "metadata": {
        "id": "Qgl0mYw6ERSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "tl_u2R9fEgwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting_clf = VotingClassifier(estimators=[ ('LRCV', classifier),('MultinomialNB', classifier3)], voting='soft')"
      ],
      "metadata": {
        "id": "ahYxI8MOEjKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t = tfidf.fit_transform(X)\n",
        "X_t = pd.DataFrame(X_t.todense(),\n",
        "    columns=tfidf.get_feature_names())"
      ],
      "metadata": {
        "id": "fNYnNEMuG3WZ",
        "outputId": "ea6521de-7644-42a8-d818-8a5685a8c8a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting_clf.fit(X_t, y) # training"
      ],
      "metadata": {
        "id": "Yxc9b17YEyLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = tfidf.transform(X_pred)\n",
        "X_pred = pd.DataFrame(X_pred.todense(),\n",
        "    columns=tfidf.get_feature_names())"
      ],
      "metadata": {
        "id": "0U7Z7oBiH6UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = soft_voting_clf.predict(X_pred)\n",
        "\n",
        "predictions = pd.DataFrame(predictions,columns=['difficulty'])\n",
        "\n",
        "predictions.to_csv(\"combi_LinearSVC_MultinomialNB.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "T_CwQkH1E5gk",
        "outputId": "f6d04adf-7121-48f4-f0b4-3c3da90a43a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-538d37d17b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_voting_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'difficulty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"combi_LinearSVC_MultinomialNB.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"soft\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mmaj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         avg = np.average(\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights_not_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         )\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
          ]
        }
      ]
    }
  ]
}